<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/page/5/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-HBase" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/02/04/HBase/" class="article-date">
  <time datetime="2019-02-04T12:16:13.908Z" itemprop="datePublished">2019-02-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h1><h2 id="HBase-核心概念介绍"><a href="#HBase-核心概念介绍" class="headerlink" title="HBase 核心概念介绍"></a>HBase 核心概念介绍</h2><h3 id="什么是hbase？"><a href="#什么是hbase？" class="headerlink" title="什么是hbase？"></a>什么是hbase？</h3><p>HBase是一个开源的非关系型分布式数据库（NoSQL），它参考了谷歌的BigTable建模，实现的编程语言为 Java。它是Apache软件基金会的Hadoop项目的一部分，运行于HDFS文件系统之上，为 Hadoop 提供类似于BigTable 规模的服务。因此，它可以对稀疏文件提供极高的容错率。HBase在列上实现了BigTable论文提到的压缩算法、内存操作和布隆过滤器。HBase的表能够作为MapReduce任务的输入和输出，可以通过JavaAPI来访问数据，也可以通过REST、Avro或者Thrift的API来访问。<br>虽然最近性能有了显著的提升，HBase 还不能直接取代SQL数据库。如今，它已经应用于多个数据驱动型网站，包括 Facebook的消息平台。在 Eric Brewer的CAP理论中，HBase属于CP类型的系统。</p>
<h3 id="HBASE表模型"><a href="#HBASE表模型" class="headerlink" title="HBASE表模型"></a>HBASE表模型</h3><p>1、hbase的表模型跟mysql之类的关系型数据库的表模型差别巨大<br>2、hbase的表模型中有：行的概念；但没有字段的概念<br>3、行中存的都是key-value对，每行中的key-value对中的key可以是各种各样，每行中的key-value对的数量也可以是各种各样</p>
<h3 id="hbase表模型的要点"><a href="#hbase表模型的要点" class="headerlink" title="hbase表模型的要点"></a>hbase表模型的要点</h3><p>1、一个表，有表名<br>2、一个表可以分为多个列族（不同列族的数据会存储在不同文件中）<br>3、表中的每一行有一个“行键rowkey”，而且行键在表中不能重复<br>4、表中的每一对kv数据称作一个cell<br>5、hbase可以对数据存储多个历史版本（历史版本数量可配置）<br>6、整张表由于数据量过大，会被横向切分成若干个region（用rowkey范围标识），不同region的数据也存储在不同文件中</p>
<h3 id="概念特性"><a href="#概念特性" class="headerlink" title="概念特性"></a>概念特性</h3><p>HBASE与mysql、oralce、db2、sqlserver等关系型数据库不同，它是一个NoSQL数据库（非关系型数据库）HBASE相比于其他nosql数据库(mongodb、redis、cassendra、hazelcast)的特点：<br>Hbase的表数据存储在HDFS文件系统中从而，hbase具备如下特性：存储容量可以线性扩展； 数据存储的安全性可靠性极高！</p>
<ul>
<li><p>Hbase的表模型与关系型数据库的表模型不同</p>
</li>
<li><p>Hbase的表没有固定的字段定义</p>
</li>
<li><p>Hbase的表中每行存储的都是一些key-value对</p>
</li>
<li><p>Hbase的表中有列族的划分，用户可以指定将哪些kv插入哪个列族</p>
</li>
<li><p>Hbase的表在物理存储上，是按照列族来分割的，不同列族的数据一定存储在不同的文件中</p>
</li>
<li><p>Hbase的表中的每一行都固定有一个行键，而且每一行的行键在表中不能重复</p>
</li>
<li><p>Hbase中的数据，包含行键，包含key，包含value，都是byte[]类型，hbase不负责为用户维护数据类型</p>
</li>
<li><p>HBASE对事务的支持很差</p>
</li>
</ul>
<h1 id="HBase-核心组件"><a href="#HBase-核心组件" class="headerlink" title="HBase 核心组件"></a>HBase 核心组件</h1><p><strong>master</strong></p>
<ul>
<li><p>管理HRegionServer，实现其负载均衡。</p>
</li>
<li><p>管理和分配HRegion，比如在HRegion split时分配新的HRegion；在HRegionServer退出时迁移其负责的HRegion到其他HRegionServer上。</p>
</li>
<li><p>Admin职能创建、删除、修改Table的定义。实现DDL操作（namespace和table的增删改，column familiy的增删改等）。</p>
</li>
</ul>
<ul>
<li><p>管理namespace和table的元数据（实际存储在HDFS上）。</p>
</li>
<li><p>权限控制（ACL）。</p>
</li>
<li><p>监控集群中所有HRegionServer的状态(通过Heartbeat和监听ZooKeeper中的状态)。</p>
</li>
</ul>
<p><strong>region server</strong></p>
<ul>
<li><p>管理自己所负责的region数据的读写。</p>
</li>
<li><p>读写HDFS，管理Table中的数据。</p>
</li>
<li><p>Client直接通过HRegionServer读写数据（从HMaster中获取元数据，找到RowKey所在的HRegion/HRegionServer后）。</p>
</li>
</ul>
<h3 id="Zookeeper集群所起作用"><a href="#Zookeeper集群所起作用" class="headerlink" title="Zookeeper集群所起作用"></a>Zookeeper集群所起作用</h3><ul>
<li><p>存放整个HBase集群的元数据以及集群的状态信息。</p>
</li>
<li><p>实现HMaster主从节点的failover。</p>
</li>
</ul>
<blockquote>
<p>注： HMaster通过监听ZooKeeper中的Ephemeral节点(默认：/hbase/rs/*)来监控HRegionServer的加入和宕机。<br>在第一个HMaster连接到ZooKeeper时会创建Ephemeral节点(默认：/hbasae/master)来表示Active的HMaster，其后加进来的HMaster则监听该Ephemeral节点<br>如果当前Active的HMaster宕机，则该节点消失，因而其他HMaster得到通知，而将自身转换成Active的HMaster，在变为Active的HMaster之前，它会在/hbase/masters/下创建自己的Ephemeral节点。</p>
</blockquote>
<h3 id="HBase读写数据流程"><a href="#HBase读写数据流程" class="headerlink" title="HBase读写数据流程"></a>HBase读写数据流程</h3><p>1、在HBase 0.96以前，HBase有两个特殊的Table：-ROOT-和.META. 用来记录用户表的rowkey范围所在的的regionserver服务器；因而客户端读写数据时需要通过3次寻址请求来对数据所在的regionserver进行定位，效率低下；</p>
<p>2、而在HBase 0.96以后去掉了-ROOT- Table，只剩下这个特殊的目录表叫做Meta Table(hbase:meta)，它存储了集群中所有用户HRegion的位置信息，而ZooKeeper的节点中(/hbase/meta-region-server)存储的则直接是这个Meta Table的位置，并且这个Meta Table如以前的-ROOT- Table一样是不可split的。这样，客户端在第一次访问用户Table的流程就变成了：<br>A.从ZooKeeper(/hbase/meta-region-server)中获取hbase:meta的位置（HRegionServer的位置），缓存该位置信息。<br>B.从HRegionServer中查询用户Table对应请求的RowKey所在的HRegionServer，缓存该位置信息。<br>C.从查询到HRegionServer中读取Row。</p>
<blockquote>
<p>注：客户会缓存这些位置信息，然而第二步它只是缓存当前RowKey对应的HRegion的位置，因而如果下一个要查的RowKey不在同一个HRegion中，则需要继续查询hbase:meta所在的HRegion，然而随着时间的推移，客户端缓存的位置信息越来越多，以至于不需要再次查找hbase:meta Table的信息，除非某个HRegion因为宕机或Split被移动，此时需要重新查询并且更新缓存。</p>
</blockquote>
<ul>
<li><p>hbase:meta表存储了所有用户HRegion的位置信息：</p>
</li>
<li><p>Rowkey：tableName,regionStartKey,regionId,replicaId等；</p>
</li>
<li><p>info列族：这个列族包含三个列，他们分别是：</p>
<ul>
<li><p>info:regioninfo列：</p>
</li>
<li><p>regionId,tableName,startKey,endKey,offline,split,replicaId；</p>
</li>
<li><p>info:server列：HRegionServer对应的server:port；</p>
</li>
<li><p>info:serverstartcode列：HRegionServer的启动时间戳。</p>
</li>
</ul>
</li>
</ul>
<h3 id="region-server-内部机制"><a href="#region-server-内部机制" class="headerlink" title="region server 内部机制"></a>region server 内部机制</h3><ul>
<li><p>WAL即Write Ahead Log，在早期版本中称为HLog，它是HDFS上的一个文件，如其名字所表示的，所有写操作都会先保证将数据写入这个Log文件后，才会真正更新MemStore，最后写入HFile中。WAL文件存储在/hbase/WALs/${HRegionServer_Name}的目录中</p>
</li>
<li><p>BlockCache是一个读缓存，即“引用局部性”原理（也应用于CPU，分空间局部性和时间局部性，空间局部性是指CPU在某一时刻需要某个数据，那么有很大的概率在一下时刻它需要的数据在其附近；时间局部性是指某个数据在被访问过一次后，它有很大的概率在不久的将来会被再次的访问），将数据预读取到内存中，以提升读的性能。</p>
</li>
<li><p>HRegion是一个Table中的一个Region在一个HRegionServer中的表达。一个Table可以有一个或多个Region，他们可以在一个相同的HRegionServer上，也可以分布在不同的HRegionServer上，一个HRegionServer可以有多个HRegion，他们分别属于不同的Table。HRegion由多个Store(HStore)构成，每个HStore对应了一个Table在这个HRegion中的一个Column Family，即每个Column Family就是一个集中的存储单元，因而最好将具有相近IO特性的Column存储在一个Column Family，以实现高效读取(数据局部性原理，可以提高缓存的命中率)。HStore是HBase中存储的核心，它实现了读写HDFS功能，一个HStore由一个MemStore 和0个或多个StoreFile组成。</p>
</li>
<li><p>MemStore是一个写缓存(In Memory Sorted Buffer)，所有数据的写在完成WAL日志写后，会 写入MemStore中，由MemStore根据一定的算法将数据Flush到地层HDFS文件中(HFile)，通常每个HRegion中的每个 Column Family有一个自己的MemStore。</p>
</li>
<li><p>HFile(StoreFile) 用于存储HBase的数据(Cell/KeyValue)。在HFile中的数据是按RowKey、Column Family、Column排序，对相同的Cell(即这三个值都一样)，则按timestamp倒序排列。</p>
</li>
<li><p>FLUSH详述</p>
<ul>
<li><p>每一次Put/Delete请求都是先写入到MemStore中，当MemStore满后会Flush成一个新的StoreFile(底层实现是HFile)，即一个HStore(Column Family)可以有0个或多个StoreFile(HFile)。</p>
</li>
<li><p>当一个HRegion中的所有MemStore的大小总和超过了hbase.hregion.memstore.flush.size的大小，默认128MB。此时当前的HRegion中所有的MemStore会Flush到HDFS中。</p>
</li>
<li><p>当全局MemStore的大小超过了hbase.regionserver.global.memstore.upperLimit的大小，默认40％的内存使用量。此时当前HRegionServer中所有HRegion中的MemStore都会Flush到HDFS中，Flush顺序是MemStore大小的倒序（一个HRegion中所有MemStore总和作为该HRegion的MemStore的大小还是选取最大的MemStore作为参考？有待考证），直到总体的MemStore使用量低于hbase.regionserver.global.memstore.lowerLimit，默认38%的内存使用量。</p>
</li>
<li><p>当前HRegionServer中WAL的大小超过了<br>hbase.regionserver.hlog.blocksize <em> hbase.regionserver.max.logs<br>的数量，当前HRegionServer中所有HRegion中的MemStore都会Flush到HDFS中，<br>Flush使用时间顺序，最早的MemStore先Flush直到WAL的数量少于<br>hbase.regionserver.hlog.blocksize </em> hbase.regionserver.max.logs<br>这里说这两个相乘的默认大小是2GB，查代码，hbase.regionserver.max.logs默认值是32，而hbase.regionserver.hlog.blocksize默认是32MB。但不管怎么样，因为这个大小超过限制引起的Flush不是一件好事，可能引起长时间的延迟</p>
</li>
</ul>
</li>
</ul>
<h2 id="HBase-安装和使用"><a href="#HBase-安装和使用" class="headerlink" title="HBase 安装和使用"></a>HBase 安装和使用</h2><p><strong>hbase安装</strong></p>
<p>HBASE是一个分布式系统，其中有一个管理角色： HMaster(一般2台，一台active，一台backup)<br>其他的数据节点角色：HRegionServer(很多台，看数据容量)</p>
<p>首先，要有一个HDFS集群，并正常运行； regionserver应该跟hdfs中的datanode在一起<br>其次，还需要一个zookeeper集群，并正常运行<br>然后，安装HBASE</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"># 下载</span><br><span class="line">wget http://archive.apache.org/dist/hbase/hbase-1.2.9/hbase-1.2.9-bin.tar.gz</span><br><span class="line"></span><br><span class="line"># 解压</span><br><span class="line">tar -zxvf hbase-1.2.9-bin.tar.gz -C /xxx/xxx </span><br><span class="line"></span><br><span class="line"># 修改$HBASE_HOME/bin/hbase-env.sh文件修改配置如下</span><br><span class="line">export JAVA_HOME=/usr/local/jdk1.8.0_192</span><br><span class="line">export HBASE_MANAGES_ZK=false</span><br><span class="line"></span><br><span class="line"># 修改或新建$HBASE_HOME/bin/hbase-site.xml文件</span><br><span class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 指定hbase在HDFS上存储的路径 --&gt;</span><br><span class="line">　　&lt;property&gt;</span><br><span class="line">　　　　&lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">　　　　&lt;value&gt;hdfs://node-1:9000/hbase&lt;/value&gt;</span><br><span class="line">　　&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 指定hbase是分布式的 --&gt;</span><br><span class="line">　　&lt;property&gt;</span><br><span class="line">　　　　&lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">　　　　&lt;value&gt;true&lt;/value&gt;</span><br><span class="line">　　&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 指定zk的地址，多个用“,”分割 --&gt;</span><br><span class="line">　　&lt;property&gt;</span><br><span class="line">　　　　&lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">　　　　&lt;value&gt;node-2,node-3,node-4&lt;/value&gt;</span><br><span class="line">　　&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 修改 $HBASE_HOME/bin/regionservers文件（配置的是regionserver节点）</span><br><span class="line">node-2</span><br><span class="line">node-3</span><br><span class="line">node-4</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 启动集群</span><br><span class="line"></span><br><span class="line">$HBASE_HOME/bin/start-hbase.sh</span><br><span class="line">启动完后，还可以在集群中找任意一台机器启动一个备用的master</span><br><span class="line">$HBASE_HOME/bin/hbase-daemon.sh start master</span><br><span class="line">新启的这个master会处于backup状态</span><br><span class="line"></span><br><span class="line"># 启动hbase的命令行客户端</span><br><span class="line"></span><br><span class="line">$HBASE_HOME/bin/hbase shell</span><br><span class="line">Hbase&gt; list     // 查看表</span><br><span class="line">Hbase&gt; status   // 查看集群状态</span><br><span class="line">Hbase&gt; version  // 查看集群版本</span><br></pre></td></tr></table></figure>
<h3 id="常用shell命令"><a href="#常用shell命令" class="headerlink" title="常用shell命令"></a>常用shell命令</h3><table>
<thead>
<tr>
<th>command</th>
<th>操作</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>alter</td>
<td>alter ‘t_test’,’f4’</td>
<td>修改列族（column family）模式</td>
</tr>
<tr>
<td>count</td>
<td>count ‘t_test’</td>
<td>统计表中行的数量</td>
</tr>
<tr>
<td>create</td>
<td>create ‘t_test’,{NAME=&gt;’f1’,VERSION=&gt;2},{NAME=&gt;’f2’,VERSION=&gt;2}</td>
<td>创建表</td>
</tr>
<tr>
<td>describe</td>
<td>describe ‘t_test’</td>
<td>显示表相关的详细信息</td>
</tr>
<tr>
<td>delete</td>
<td>delete ‘t_test’,’r1’,’f1:c1’</td>
<td>删除指定对象的值（可以为表，行，列对应的值，另外也可以指定时间戳的值）</td>
</tr>
<tr>
<td>deleteall</td>
<td>deleteall ‘t_test’,’r1’</td>
<td>删除指定行的所有元素值</td>
</tr>
<tr>
<td>disable</td>
<td>disable ‘t_test’</td>
<td>使表无效</td>
</tr>
<tr>
<td>drop</td>
<td>drop ‘t_test’</td>
<td>删除表(需要先禁用表)</td>
</tr>
<tr>
<td>enable</td>
<td>enable ‘t_test’</td>
<td>使表有效</td>
</tr>
<tr>
<td>exists</td>
<td>exists ‘t_test’</td>
<td>测试表是否存在</td>
</tr>
<tr>
<td>exit</td>
<td>exit</td>
<td>退出hbase shell</td>
</tr>
<tr>
<td>get</td>
<td>get ‘t_test’,’r2’</td>
<td>获取行或单元（cell）的值</td>
</tr>
<tr>
<td>list</td>
<td>list</td>
<td>列出hbase中存在的所有表</td>
</tr>
<tr>
<td>put</td>
<td>put ‘t_test’,’r2’,’f1:c1’,’v2’</td>
<td>向指向的表单元添加值</td>
</tr>
<tr>
<td>tools</td>
<td>tools</td>
<td>列出hbase所支持的工具</td>
</tr>
<tr>
<td>scan</td>
<td>scan ‘t_test’</td>
<td>通过对表的扫描来获取对用的值</td>
</tr>
<tr>
<td>status</td>
<td>status</td>
<td>返回hbase集群的状态信息</td>
</tr>
<tr>
<td>shutdown</td>
<td>shutdown</td>
<td>关闭hbase集群（与exit不同）</td>
</tr>
<tr>
<td>version</td>
<td>version</td>
<td>返回hbase版本信息</td>
</tr>
<tr>
<td>truncate</td>
<td>truncate ‘t_person’</td>
<td>清空表数据       </td>
</tr>
<tr>
<td>desc</td>
<td>desc ‘t_person’</td>
<td>查看表结构</td>
</tr>
</tbody>
</table>
<h2 id="java-api-操作hbase"><a href="#java-api-操作hbase" class="headerlink" title="java api 操作hbase"></a>java api 操作hbase</h2><ul>
<li>pom.xml</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;</span><br><span class="line">         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span><br><span class="line">         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;</span><br><span class="line"></span><br><span class="line">    &lt;artifactId&gt;bit-data-hbase&lt;/artifactId&gt;</span><br><span class="line">    &lt;groupId&gt;com.andy&lt;/groupId&gt;</span><br><span class="line">    &lt;version&gt;1.0.1.RELEASE&lt;/version&gt;</span><br><span class="line"></span><br><span class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;hbase-client&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.2.9&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;com.andy&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;big-data-common&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.0.1.RELEASE&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line"></span><br><span class="line">    &lt;build&gt;</span><br><span class="line">        &lt;plugins&gt;</span><br><span class="line">            &lt;plugin&gt;</span><br><span class="line">                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;</span><br><span class="line">                &lt;version&gt;3.7.0&lt;/version&gt;</span><br><span class="line">                &lt;configuration&gt;</span><br><span class="line">                    &lt;source&gt;1.8&lt;/source&gt;</span><br><span class="line">                    &lt;target&gt;1.8&lt;/target&gt;</span><br><span class="line">                    &lt;encoding&gt;UTF-8&lt;/encoding&gt;</span><br><span class="line">                &lt;/configuration&gt;</span><br><span class="line">            &lt;/plugin&gt;</span><br><span class="line">        &lt;/plugins&gt;</span><br><span class="line">    &lt;/build&gt;</span><br><span class="line">&lt;/project&gt;</span><br></pre></td></tr></table></figure>
<ul>
<li>hbase DDL操作</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.hbase.HBaseConfiguration;</span><br><span class="line">import org.apache.hadoop.hbase.HColumnDescriptor;</span><br><span class="line">import org.apache.hadoop.hbase.HTableDescriptor;</span><br><span class="line">import org.apache.hadoop.hbase.TableName;</span><br><span class="line">import org.apache.hadoop.hbase.client.Admin;</span><br><span class="line">import org.apache.hadoop.hbase.client.Connection;</span><br><span class="line">import org.apache.hadoop.hbase.client.ConnectionFactory;</span><br><span class="line">import org.apache.hadoop.hbase.regionserver.BloomType;</span><br><span class="line">import org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line">import org.junit.Before;</span><br><span class="line">import org.junit.Test;</span><br><span class="line">import org.slf4j.Logger;</span><br><span class="line">import org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * &lt;p&gt; HBase ddl 操作</span><br><span class="line"> *</span><br><span class="line"> * @author leone</span><br><span class="line"> * @since 2018-12-16</span><br><span class="line"> **/</span><br><span class="line">public class HBaseClientTest &#123;</span><br><span class="line"></span><br><span class="line">    private static final Logger logger = LoggerFactory.getLogger(HBaseCrudTest.class);</span><br><span class="line"></span><br><span class="line">    private Connection conn;</span><br><span class="line"></span><br><span class="line">    private Admin admin;</span><br><span class="line"></span><br><span class="line">    private String tableName = &quot;t_person&quot;;</span><br><span class="line"></span><br><span class="line">    private String f1 = &quot;f1&quot;;</span><br><span class="line"></span><br><span class="line">    private String f2 = &quot;f2&quot;;</span><br><span class="line"></span><br><span class="line">    private String f3 = &quot;f3&quot;;</span><br><span class="line"></span><br><span class="line">    @Before</span><br><span class="line">    public void init() throws Exception &#123;</span><br><span class="line">        // 创建连接对象,会自动加载HBase配置文件 zookeeper集群的URL配置信息</span><br><span class="line">        Configuration conf = HBaseConfiguration.create();</span><br><span class="line">        conf.set(&quot;hbase.zookeeper.quorum&quot;, &quot;node-2:2181,node-3:2181,node-4:2181&quot;);</span><br><span class="line">        conn = ConnectionFactory.createConnection(conf);</span><br><span class="line">        // 创建ddl描述对象</span><br><span class="line">        admin = conn.getAdmin();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 创建表</span><br><span class="line">     * create &apos;t_person&apos;,&apos;f1&apos;,&apos;f2&apos;,&apos;f3&apos;</span><br><span class="line">     *</span><br><span class="line">     * @throws Exception</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    public void createTableTest() throws Exception &#123;</span><br><span class="line">        // 创建表描述对象</span><br><span class="line">        HTableDescriptor table = new HTableDescriptor(TableName.valueOf(tableName));</span><br><span class="line"></span><br><span class="line">        // 创建列簇描述对象</span><br><span class="line">        HColumnDescriptor column1 = new HColumnDescriptor(f1);</span><br><span class="line">        // 设置保存数据的最大半本数量是3</span><br><span class="line">        column1.setMaxVersions(3);</span><br><span class="line"></span><br><span class="line">        HColumnDescriptor column2 = new HColumnDescriptor(f2);</span><br><span class="line"></span><br><span class="line">        table.addFamily(column1);</span><br><span class="line">        table.addFamily(column2);</span><br><span class="line"></span><br><span class="line">        admin.createTable(table);</span><br><span class="line"></span><br><span class="line">        admin.close();</span><br><span class="line">        conn.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 删除表</span><br><span class="line">     * disable &apos;t_person&apos;</span><br><span class="line">     * drop &apos;t_person&apos;</span><br><span class="line">     *</span><br><span class="line">     * @throws Exception</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    public void dropTableTest() throws Exception &#123;</span><br><span class="line">        // 先停用表</span><br><span class="line">        admin.disableTable(TableName.valueOf(tableName));</span><br><span class="line"></span><br><span class="line">        // 再删除表</span><br><span class="line">        admin.deleteTable(TableName.valueOf(tableName));</span><br><span class="line"></span><br><span class="line">        admin.close();</span><br><span class="line">        conn.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 修改表添加列簇</span><br><span class="line">     * alter &apos;t_person&apos;,&apos;f4&apos;</span><br><span class="line">     *</span><br><span class="line">     * @throws Exception</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    public void modifyTableTest() throws Exception &#123;</span><br><span class="line">        // 取出旧的的表的描述信息</span><br><span class="line">        HTableDescriptor table = admin.getTableDescriptor(TableName.valueOf(tableName));</span><br><span class="line"></span><br><span class="line">        HColumnDescriptor column = new HColumnDescriptor(f3);</span><br><span class="line">        // 设置布隆过滤器</span><br><span class="line">        column.setBloomFilterType(BloomType.ROWCOL);</span><br><span class="line"></span><br><span class="line">        table.addFamily(column);</span><br><span class="line"></span><br><span class="line">        admin.modifyTable(TableName.valueOf(tableName), table);</span><br><span class="line"></span><br><span class="line">        admin.close();</span><br><span class="line">        conn.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 查看表定义信息</span><br><span class="line">     * desc &apos;t_person&apos;</span><br><span class="line">     *</span><br><span class="line">     * @throws Exception</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    public void descTableTest() throws Exception &#123;</span><br><span class="line">        HTableDescriptor table = admin.getTableDescriptor(TableName.valueOf(tableName));</span><br><span class="line">        HColumnDescriptor[] columnFamilies = table.getColumnFamilies();</span><br><span class="line">        for (HColumnDescriptor hcd : columnFamilies) &#123;</span><br><span class="line">            logger.info(&quot;HColumn: &#123;&#125;&quot;, Bytes.toString(hcd.getName()));</span><br><span class="line">        &#125;</span><br><span class="line">        admin.close();</span><br><span class="line">        conn.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>hbase CRUD测试</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br></pre></td><td class="code"><pre><span class="line">import com.andy.common.utils.RandomValue;</span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.hbase.*;</span><br><span class="line">import org.apache.hadoop.hbase.client.*;</span><br><span class="line">import org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line">import org.junit.Before;</span><br><span class="line">import org.junit.Test;</span><br><span class="line">import org.slf4j.Logger;</span><br><span class="line">import org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line">import java.util.ArrayList;</span><br><span class="line">import java.util.Iterator;</span><br><span class="line">import java.util.List;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * &lt;p&gt; HBase crud</span><br><span class="line"> *</span><br><span class="line"> * @author leone</span><br><span class="line"> * @since 2018-12-16</span><br><span class="line"> **/</span><br><span class="line">public class HBaseCrudTest &#123;</span><br><span class="line"></span><br><span class="line">    private static final Logger logger = LoggerFactory.getLogger(HBaseCrudTest.class);</span><br><span class="line"></span><br><span class="line">    private String tableName = &quot;t_person&quot;;</span><br><span class="line"></span><br><span class="line">    private String f1 = &quot;f1&quot;, f2 = &quot;f2&quot;, f3 = &quot;f3&quot;;</span><br><span class="line"></span><br><span class="line">    private Connection conn;</span><br><span class="line"></span><br><span class="line">    private Configuration conf;</span><br><span class="line"></span><br><span class="line">    @Before</span><br><span class="line">    public void init() throws Exception &#123;</span><br><span class="line">        // 创建连接对象,会自动加载HBase配置文件</span><br><span class="line">        conf = HBaseConfiguration.create();</span><br><span class="line">        conf.set(&quot;hbase.zookeeper.quorum&quot;, &quot;node-2:2181,node-3:2181,node-4:2181&quot;);</span><br><span class="line">        conn = ConnectionFactory.createConnection(conf);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * DML 操作，向 HBase 插入数据</span><br><span class="line">     * put &apos;t_person&apos;,&apos;r2&apos;,&apos;f1:c1&apos;,&apos;v1&apos;</span><br><span class="line">     *</span><br><span class="line">     * @throws Exception</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    public void insertTest() throws Exception &#123;</span><br><span class="line">        // 获取指定表对象，进行dml操作</span><br><span class="line">        Table table = conn.getTable(TableName.valueOf(tableName));</span><br><span class="line">        List&lt;Put&gt; rows = new ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        for (int i = 1; i &lt;= 20; i++) &#123;</span><br><span class="line">            Put row = new Put(Bytes.toBytes(String.valueOf(i)));</span><br><span class="line">            row.addColumn(Bytes.toBytes(f1), Bytes.toBytes(&quot;name&quot;), Bytes.toBytes(RandomValue.getName()));</span><br><span class="line">            row.addColumn(Bytes.toBytes(f1), Bytes.toBytes(&quot;age&quot;), Bytes.toBytes(String.valueOf(RandomValue.getNumber(50))));</span><br><span class="line">            row.addColumn(Bytes.toBytes(f2), Bytes.toBytes(&quot;address&quot;), Bytes.toBytes(RandomValue.getAddress()));</span><br><span class="line">            rows.add(row);</span><br><span class="line">        &#125;</span><br><span class="line">        logger.info(&quot;size:&#123;&#125;&quot;, rows.size());</span><br><span class="line">        table.put(rows);</span><br><span class="line">        conn.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * DML 操作，删除数据 HBase 中数据</span><br><span class="line">     * delete &apos;t_person&apos;,&apos;r1&apos;,&apos;f1:c1&apos;</span><br><span class="line">     *</span><br><span class="line">     * @throws Exception</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    public void deleteTest() throws Exception &#123;</span><br><span class="line">        // 获取指定表对象，进行dml操作</span><br><span class="line">        Table table = conn.getTable(TableName.valueOf(tableName));</span><br><span class="line"></span><br><span class="line">        Delete delete1 = new Delete(Bytes.toBytes(&quot;0&quot;));</span><br><span class="line"></span><br><span class="line">        Delete delete2 = new Delete(Bytes.toBytes(&quot;1&quot;));</span><br><span class="line">        delete2.addColumn(Bytes.toBytes(f1), Bytes.toBytes(&quot;name&quot;));</span><br><span class="line"></span><br><span class="line">        List&lt;Delete&gt; deleteList = new ArrayList&lt;&gt;();</span><br><span class="line">        deleteList.add(delete1);</span><br><span class="line">        deleteList.add(delete2);</span><br><span class="line"></span><br><span class="line">        table.delete(deleteList);</span><br><span class="line"></span><br><span class="line">        conn.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * DML 操作，删除数据 HBase 中数据</span><br><span class="line">     * deleteall &apos;t_person&apos;,&apos;r1&apos;</span><br><span class="line">     *</span><br><span class="line">     * @throws Exception</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    public void deleteAllTest() throws Exception &#123;</span><br><span class="line">        // 获取指定表对象，进行dml操作</span><br><span class="line">        Table table = conn.getTable(TableName.valueOf(tableName));</span><br><span class="line"></span><br><span class="line">        Delete delete = new Delete(Bytes.toBytes(&quot;3&quot;));</span><br><span class="line"></span><br><span class="line">        table.delete(delete);</span><br><span class="line"></span><br><span class="line">        conn.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * DML 操作，修改数据 HBase 中数据</span><br><span class="line">     *</span><br><span class="line">     * @throws Exception</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    public void updateTest() throws Exception &#123;</span><br><span class="line">        // 获取指定表对象，进行dml操作</span><br><span class="line">        Table table = conn.getTable(TableName.valueOf(tableName));</span><br><span class="line"></span><br><span class="line">        conn.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * DML 操作 HBase 查询数据</span><br><span class="line">     * get &apos;t_person&apos;,&apos;r2&apos;</span><br><span class="line">     *</span><br><span class="line">     * @throws Exception</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    public void getTest() throws Exception &#123;</span><br><span class="line">        // 获取指定表对象，进行dml操作</span><br><span class="line">        Table table = conn.getTable(TableName.valueOf(tableName));</span><br><span class="line">        List&lt;Get&gt; gets = new ArrayList&lt;&gt;();</span><br><span class="line">        for (int i = 1; i &lt;= 20; i++) &#123;</span><br><span class="line">            Get get = new Get(Bytes.toBytes(String.valueOf(i)));</span><br><span class="line">            gets.add(get);</span><br><span class="line">        &#125;</span><br><span class="line">        Result[] results = table.get(gets);</span><br><span class="line">        for (Result result : results) &#123;</span><br><span class="line">            CellScanner cellScanner = result.cellScanner();</span><br><span class="line">            while (cellScanner.advance()) &#123;</span><br><span class="line">                Cell cell = cellScanner.current();</span><br><span class="line">                // 行键的字节数组</span><br><span class="line">                byte[] rowArray = cell.getRowArray();</span><br><span class="line">                // 列簇的字节数组</span><br><span class="line">                byte[] familyArray = cell.getFamilyArray();</span><br><span class="line">                // 列名的字节数组</span><br><span class="line">                byte[] qualifierArray = cell.getQualifierArray();</span><br><span class="line">                // value的字节数组</span><br><span class="line">                byte[] valueArray = cell.getValueArray();</span><br><span class="line">                logger.info(&quot;行键:&#123;&#125; \t 列簇:&#123;&#125; \t key:&#123;&#125; \t value:&#123;&#125;&quot;, new Object[]&#123;new String(rowArray, cell.getRowOffset(), cell.getRowLength()), new String(familyArray, cell.getFamilyOffset(), cell.getFamilyLength()), new String(qualifierArray, cell.getQualifierOffset(), cell.getQualifierLength()), new String(valueArray, cell.getValueOffset(), cell.getValueLength())&#125;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        conn.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * DML 操作 HBase 查询数据</span><br><span class="line">     * scan &apos;t_person&apos;</span><br><span class="line">     *</span><br><span class="line">     * @throws Exception</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    public void scanTest() throws Exception &#123;</span><br><span class="line">        // 获取指定表对象，进行dml操作</span><br><span class="line">        Table table = conn.getTable(TableName.valueOf(tableName));</span><br><span class="line">        // 可以指定开始行键和结束行键</span><br><span class="line">        Scan scan = new Scan(Bytes.toBytes(&quot;2&quot;), Bytes.toBytes(&quot;3&quot;));</span><br><span class="line"></span><br><span class="line">        ResultScanner result = table.getScanner(scan);</span><br><span class="line"></span><br><span class="line">        Iterator&lt;Result&gt; iterator = result.iterator();</span><br><span class="line">        while (iterator.hasNext()) &#123;</span><br><span class="line">            Result rs = iterator.next();</span><br><span class="line">            CellScanner cellScanner = rs.cellScanner();</span><br><span class="line">            while (cellScanner.advance()) &#123;</span><br><span class="line">                Cell cell = cellScanner.current();</span><br><span class="line">                byte[] rowArray = cell.getRowArray();</span><br><span class="line">                // 列簇的字节数组</span><br><span class="line">                byte[] familyArray = cell.getFamilyArray();</span><br><span class="line">                // 列名的字节数组</span><br><span class="line">                byte[] qualifierArray = cell.getQualifierArray();</span><br><span class="line">                // value的字节数组</span><br><span class="line">                byte[] valueArray = cell.getValueArray();</span><br><span class="line">                logger.info(&quot;行键:&#123;&#125; \t 列簇:&#123;&#125; \t key:&#123;&#125; \t value:&#123;&#125;&quot;, new Object[]&#123;new String(rowArray, cell.getRowOffset(), cell.getRowLength()), new String(familyArray, cell.getFamilyOffset(), cell.getFamilyLength()), new String(qualifierArray, cell.getQualifierOffset(), cell.getQualifierLength()), new String(valueArray, cell.getValueOffset(), cell.getValueLength())&#125;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        conn.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 查询某列数据的某个版本</span><br><span class="line">     *</span><br><span class="line">     * @throws Exception</span><br><span class="line">     */</span><br><span class="line">    @Test</span><br><span class="line">    public void getVersionTest() throws Exception &#123;</span><br><span class="line">        HTable htable = new HTable(conf, tableName);</span><br><span class="line"></span><br><span class="line">        Get get = new Get(Bytes.toBytes(&quot;2&quot;));</span><br><span class="line"></span><br><span class="line">        get.addColumn(Bytes.toBytes(f1), Bytes.toBytes(&quot;name&quot;));</span><br><span class="line">        get.setMaxVersions(2);</span><br><span class="line">        Result result = htable.get(get);</span><br><span class="line">        for (KeyValue cell : result.list()) &#123;</span><br><span class="line">            byte[] rowArray = cell.getRowArray();</span><br><span class="line">            // 列簇的字节数组</span><br><span class="line">            byte[] familyArray = cell.getFamilyArray();</span><br><span class="line">            // 列名的字节数组</span><br><span class="line">            byte[] qualifierArray = cell.getQualifierArray();</span><br><span class="line">            // value的字节数组</span><br><span class="line">            byte[] valueArray = cell.getValueArray();</span><br><span class="line">            logger.info(&quot;行键:&#123;&#125; \t 列簇:&#123;&#125; \t key:&#123;&#125; \t value:&#123;&#125; \ttimestamp:&#123;&#125;&quot;, new Object[]&#123;new String(rowArray, cell.getRowOffset(), cell.getRowLength()), new String(familyArray, cell.getFamilyOffset(), cell.getFamilyLength()), new String(qualifierArray, cell.getQualifierOffset(), cell.getQualifierLength()), new String(valueArray, cell.getValueOffset(), cell.getValueLength()), cell.getTimestamp()&#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        conn.close();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/02/04/HBase/" data-id="cjrqbftzc0015akc4alp2tlfz" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-hadoop" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/02/04/hadoop/" class="article-date">
  <time datetime="2019-02-04T12:16:13.883Z" itemprop="datePublished">2019-02-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>title: hadoop<br>date: 2018-01-05 16:31:12<br>tags: [linux, 大数据, hadoop]<br>categories: hadoop</p>
<h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><h2 id="Hadoop背景"><a href="#Hadoop背景" class="headerlink" title="Hadoop背景"></a>Hadoop背景</h2><h3 id="什么是HADOOP"><a href="#什么是HADOOP" class="headerlink" title="什么是HADOOP"></a>什么是HADOOP</h3><p>HADOOP是apache旗下的一套开源软件平台HADOOP提供利用服务器集群，根据用户的自定义业务逻辑，对海量数据进行分布式处理,HADOOP的核心组件有:HDFS（分布式文件系统）、YARN（运算资源调度系统）、MAPREDUCE（分布式运算编程框架），广义上来说，HADOOP通常是指一个更广泛的概念——HADOOP生态圈</p>
<h3 id="HADOOP产生背景"><a href="#HADOOP产生背景" class="headerlink" title="HADOOP产生背景"></a>HADOOP产生背景</h3><p>HADOOP最早起源于Nutch。Nutch的设计目标是构建一个大型的全网搜索引擎，包括网页抓取、索引、查询等功能，但随着抓取网页数量的增加，遇到了严重的可扩展性问题——如何解决数十亿网页的存储和索引问题。2003年、2004年谷歌发表的两篇论文为该问题提供了可行的解决方案。——分布式文件系统（GFS），可用于处理海量网页的存储——分布式计算框架MAPREDUCE，可用于处理海量网页的索引计算问题。Nutch的开发人员完成了相应的开源实现HDFS和MAPREDUCE，并从Nutch中剥离成为独立项目HADOOP，到2008年1月，HADOOP成为Apache顶级项目，迎来了它的快速发展期。</p>
<h3 id="HADOOP在大数据、云计算中的位置和关系"><a href="#HADOOP在大数据、云计算中的位置和关系" class="headerlink" title="HADOOP在大数据、云计算中的位置和关系"></a>HADOOP在大数据、云计算中的位置和关系</h3><ul>
<li><p>云计算是分布式计算、并行计算、网格计算、多核计算、网络存储、虚拟化、负载均衡等传统计算机技术和互联网技术融合发展的产物。借助IaaS(基础设施即服务)、PaaS(平台即服务)、SaaS（软件即服务）等业务模式，把强大的计算能力提供给终端用户。</p>
</li>
<li><p>现阶段，云计算的两大底层支撑技术为“虚拟化”和“大数据技术”</p>
</li>
<li><p>而HADOOP则是云计算的PaaS层的解决方案之一，并不等同于PaaS，更不等同于云计算本身。</p>
</li>
</ul>
<h3 id="HADOOP生态圈以及各组成部分的简介"><a href="#HADOOP生态圈以及各组成部分的简介" class="headerlink" title="HADOOP生态圈以及各组成部分的简介"></a>HADOOP生态圈以及各组成部分的简介</h3><ul>
<li>HDFS：分布式文件系统</li>
<li>MAPREDUCE：分布式运算程序开发框架</li>
<li>HIVE：基于大数据技术（文件系统+运算框架）的SQL数据仓库工具</li>
<li>HBASE：基于HADOOP的分布式海量数据库</li>
<li>ZOOKEEPER：分布式协调服务基础组件</li>
<li>Mahout：基于mapreduce/spark/flink等分布式运算框架的机器学习算法库</li>
<li>Oozie：工作流调度框架</li>
<li>Sqoop：数据导入导出工具</li>
<li>Flume：日志数据采集框架</li>
</ul>
<h2 id="分布式系统概述"><a href="#分布式系统概述" class="headerlink" title="分布式系统概述"></a>分布式系统概述</h2><p><strong>注：由于大数据技术领域的各类技术框架基本上都是分布式系统，因此，理解hadoop、storm、spark等技术框架，都需要具备基本的分布式系统概念</strong></p>
<h3 id="什么是分布式"><a href="#什么是分布式" class="headerlink" title="什么是分布式"></a>什么是分布式</h3><p>分布式系统是由一组通过网络进行通信、为了完成共同的任务而协调工作的计算机节点组成的系统。分布式系统的出现是为了用廉价的、普通的机器完成单个计算机无法完成的计算、存储任务。其目的是利用更多的机器，处理更多的数据 。分布式系统的特点是：硬件独立，各设备之间独立，互不依赖、 软件统一，对用户来说，就像是跟单个系统打交道。</p>
<h2 id="为什么需要分布式"><a href="#为什么需要分布式" class="headerlink" title="为什么需要分布式"></a>为什么需要分布式</h2><p>为了性能扩展：系统负载高，单台机器无法承受，希望通过多台机器来提高系统负载能力 为了增强可靠性：软件不是完美的，网络不是完美的，甚至机器也不是完美的，随时可能出错，为了避免故障，需要将业务分散开保留一定的冗余度</p>
<h3 id="分布式软件系统-Distributed-Software-Systems"><a href="#分布式软件系统-Distributed-Software-Systems" class="headerlink" title="分布式软件系统(Distributed Software Systems)"></a>分布式软件系统(Distributed Software Systems)</h3><ol>
<li><p>该软件系统会划分成多个子系统或模块，各自运行在不同的机器上，子系统或模块之间通过网络通信进行协作，实现最终的整体功能</p>
</li>
<li><p>比如分布式操作系统、分布式程序设计语言及其编译(解释)系统、分布式文件系统和分布式数据库系统等。</p>
</li>
</ol>
<h3 id="分布式软件系统举例：solrcloud"><a href="#分布式软件系统举例：solrcloud" class="headerlink" title="分布式软件系统举例：solrcloud"></a>分布式软件系统举例：solrcloud</h3><ul>
<li><p>一个solrcloud集群通常有多台solr服务器</p>
</li>
<li><p>每一个solr服务器节点负责存储整个索引库的若干个shard（数据分片）</p>
</li>
<li><p>每一个shard又有多台服务器存放若干个副本互为主备用</p>
</li>
<li><p>索引的建立和查询会在整个集群的各个节点上并发执行</p>
</li>
<li><p>solrcloud集群作为整体对外服务，而其内部细节可对客户端透明</p>
</li>
</ul>
<p><strong>总结：利用多个节点共同协作完成一项或多项具体业务功能的系统就是分布式系统。</strong></p>
<h3 id="为什么使用分布式"><a href="#为什么使用分布式" class="headerlink" title="为什么使用分布式"></a>为什么使用分布式</h3><ul>
<li>单机处理能力存在瓶颈；</li>
<li>升级单机处理能力的性价比越来越低；</li>
<li>分布式系统稳定性、可用性好</li>
</ul>
<h2 id="离线数据分析流程介绍"><a href="#离线数据分析流程介绍" class="headerlink" title="离线数据分析流程介绍"></a>离线数据分析流程介绍</h2><blockquote>
<p>注：本环节主要感受数据分析系统的宏观概念及处理流程，初步理解hadoop等框架在其中的应用环节，不用过于关注代码细节</p>
</blockquote>
<h3 id="web日志数据挖掘"><a href="#web日志数据挖掘" class="headerlink" title="web日志数据挖掘"></a>web日志数据挖掘</h3><blockquote>
<p>“Web点击流日志”包含着网站运营很重要的信息，通过日志分析，我们可以知道网站的访问量，哪个网页访问人数最多，哪个网页最有价值，广告转化率、访客的来源信息，访客的终端信息等。</p>
</blockquote>
<h3 id="日志来源"><a href="#日志来源" class="headerlink" title="日志来源"></a>日志来源</h3><blockquote>
<p>本案例的数据主要由用户的点击行为记录<br>获取方式：在页面预埋一段js程序，为页面上想要监听的标签绑定事件，只要用户点击或移动到标签，即可触发ajax请求到后台servlet程序，用log4j记录下事件信息，从而在web服务器（nginx、tomcat等）上形成不断增长的日志文件。<br>形如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">58.215.204.118 - - [18/Sep/2013:06:51:35 +0000] &quot;GET /wp-includes/js/jquery/jquery.js?ver=1.10.2 HTTP/1.1&quot; 304 0 &quot;http://blog.fens.me/nodejs-socketio-chat/&quot; &quot;Mozilla/5.0 (Windows NT 5.1; rv:23.0) Gecko/20100101 Firefox/23.0&quot;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h3 id="流程解释"><a href="#流程解释" class="headerlink" title="流程解释"></a>流程解释</h3><ul>
<li>数据采集：定制开发采集程序，或使用开源框架FLUME</li>
<li>数据存储：你用hDFS分布式文件处理海量数据</li>
<li>数据预处理：定制开发mapreduce程序运行于hadoop集群</li>
<li>数据仓库技术：基于hadoop之上的Hive</li>
<li>数据导出：基于hadoop的sqoop数据导入导出工具</li>
<li>数据可视化：定制开发web程序或使用kettle等产品</li>
<li>整个过程的流程调度：hadoop生态圈中的oozie工具或其他类似开源产品</li>
</ul>
<h2 id="hadoop集群搭建"><a href="#hadoop集群搭建" class="headerlink" title="hadoop集群搭建"></a>hadoop集群搭建</h2><h3 id="集群简介"><a href="#集群简介" class="headerlink" title="集群简介"></a>集群简介</h3><p>HADOOP集群具体来说包含两个集群：HDFS集群和YARN集群，两者逻辑上分离，但物理上常在一起</p>
<ul>
<li>HDFS集群：负责海量数据的存储，集群中的角色主要有 NameNode / DataNode</li>
<li>YARN集群：负责海量数据运算时的资源调度，集群中的角色主要有 ResourceManager /NodeManager(那mapreduce是什么呢？它其实是一个应用程序开发包)</li>
</ul>
<p>服务器分配<br>本集群搭建案例，以5节点为例进行搭建，角色分配如下：</p>
<table>
<thead>
<tr>
<th>节点</th>
<th>进程</th>
</tr>
</thead>
<tbody>
<tr>
<td>node-1</td>
<td>NameNode  SecondaryNameNode</td>
</tr>
<tr>
<td>node-2</td>
<td>ResourceManager</td>
</tr>
<tr>
<td>node-3</td>
<td>DataNode    NodeManager</td>
</tr>
<tr>
<td>node-4</td>
<td>DataNode    NodeManager</td>
</tr>
<tr>
<td>node-5</td>
<td>DataNode    NodeManager</td>
</tr>
</tbody>
</table>
<h3 id="服务器系统配置"><a href="#服务器系统配置" class="headerlink" title="服务器系统配置"></a>服务器系统配置</h3><ol>
<li><p>配置系统网络，安装常用依赖包如文件上传、编辑器、网络工具</p>
</li>
<li><p>同步时间、配置各主机名称映射、配置ssh免密登陆</p>
</li>
<li><p>安装java环境</p>
</li>
</ol>
<h3 id="hadoop集群安装部署"><a href="#hadoop集群安装部署" class="headerlink" title="hadoop集群安装部署"></a>hadoop集群安装部署</h3><ul>
<li><p>上传HADOOP安装包并解压</p>
</li>
<li><p>规划安装目录  /export/servers/hadoop-2.7.7/</p>
</li>
<li><p>修改配置文件  $HADOOP_HOME/etc/hadoop/</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ vi /etc/profile</span><br><span class="line"></span><br><span class="line">export HADOOP_HOME=/export/servers/hadoop2.7.7</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ vi  hadoop-env.sh</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=/usr/local//jdk1.8.0_191</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ vi  core-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;   </span><br><span class="line">    &lt;property&gt;   </span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;   </span><br><span class="line">        &lt;value&gt;hdfs://hdp-node-01:9000&lt;/value&gt;   </span><br><span class="line">    &lt;/property&gt;   </span><br><span class="line">    &lt;property&gt;   </span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;   </span><br><span class="line">        &lt;value&gt;/home/HADOOP/apps/hadoop-2.6.1/tmp&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ vi  hdfs-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/home/hadoop/data/name&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/home/hadoop/data/data&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;3&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.secondary.http.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdp-node-01:50090&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ vi  mapred-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ vi  yarn-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">	&lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;node-1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ vi  salves</span><br><span class="line"></span><br><span class="line">node-3</span><br><span class="line">node-4</span><br><span class="line">node-5</span><br></pre></td></tr></table></figure>
<h3 id="启动hadoop集群"><a href="#启动hadoop集群" class="headerlink" title="启动hadoop集群"></a>启动hadoop集群</h3><p>初始化HDFS<br><code>$HADOOP_HOME/sbin/hadoop  namenode  -format</code></p>
<p>启动HDFS<br><code>$HADOOP_HOME/sbin/start-dfs.sh</code></p>
<p>启动YARN<br><code>$HADOOP_HOME/sbin/start-yarn.sh</code></p>
<p>启动所有<br><code>$HADOOP_HOME/sbin/start-all.sh</code></p>
<h3 id="测试hadoop集群"><a href="#测试hadoop集群" class="headerlink" title="测试hadoop集群"></a>测试hadoop集群</h3><p>hdfs 常用操作<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">hadoop常用命令</span><br><span class="line"></span><br><span class="line"># 查看hadoop版本</span><br><span class="line">$ hadoop verion</span><br><span class="line"></span><br><span class="line"># 运行jar文件</span><br><span class="line">$ hadoop jar</span><br><span class="line"></span><br><span class="line"># 创建文件夹</span><br><span class="line">$ hadoop fs -mkdir -p /data/input</span><br><span class="line"></span><br><span class="line"># 递归查看文件夹</span><br><span class="line">$ hadoop fs -ls -R /data/input</span><br><span class="line"></span><br><span class="line"># 上传本地文件到HDFS</span><br><span class="line">$ hadoop fs -put /root/words.txt  /data/input</span><br><span class="line"></span><br><span class="line"># 查看HDFS上的文件</span><br><span class="line">$ hadoop fs -cat /data/input/words.txt</span><br><span class="line"></span><br><span class="line"># 删除HDFS上的文件</span><br><span class="line">$ hadoop fs -rm -f /data/input/words.txt</span><br></pre></td></tr></table></figure></p>
<h3 id="运行一个mapreduce程序"><a href="#运行一个mapreduce程序" class="headerlink" title="运行一个mapreduce程序"></a>运行一个mapreduce程序</h3><blockquote>
<p>在hadoop安装目录下，运行一个示例mr程序</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cd $HADOOP_HOME/share/hadoop/mapreduce/</span><br><span class="line">$ hadoop jar hadoop-mapreduce-examples-2.7.7.jar wordcount /data/input /data/output</span><br></pre></td></tr></table></figure>
<h3 id="集群使用初步"><a href="#集群使用初步" class="headerlink" title="集群使用初步"></a>集群使用初步</h3><blockquote>
<p>可打开web控制台查看HDFS集群信息，在浏览器打开http:/node-1:50070/</p>
</blockquote>
<p>MAPREDUCE使用</p>
<ul>
<li>mapreduce是hadoop中的分布式运算编程框架，只要按照其编程规范，只需要编写少量的业务逻辑代码即可实现一个强大的海量数据并发处理程序</li>
</ul>
<h2 id="HDFS详解"><a href="#HDFS详解" class="headerlink" title="HDFS详解"></a>HDFS详解</h2><h3 id="HDFS前言"><a href="#HDFS前言" class="headerlink" title="HDFS前言"></a>HDFS前言</h3><p>设计思想</p>
<ul>
<li>分而治之：将大文件、大批量文件，分布式存放在大量服务器上，以便于采取分而治之的方式对海量数据进行运算分析；</li>
</ul>
<p>在大数据系统中作用：</p>
<ul>
<li>为各类分布式运算框架（如：mapreduce，spark，tez，……）提供数据存储服务</li>
</ul>
<p>重点概念</p>
<ul>
<li>文件切块，副本存放，元数据</li>
</ul>
<h3 id="HDFS的概念和特性"><a href="#HDFS的概念和特性" class="headerlink" title="HDFS的概念和特性"></a>HDFS的概念和特性</h3><blockquote>
<p>首先，它是一个文件系统，用于存储文件，通过统一的命名空间——目录树来定位文件<br>其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色；</p>
</blockquote>
<ul>
<li><p>重要特性如下：</p>
<ul>
<li><p>HDFS中的文件在物理上是分块存储（block），块的大小可以通过配置参数( dfs.blocksize)来规定，默认大小在hadoop2.x版本中是128M，老版本中是64M</p>
</li>
<li><p>HDFS文件系统会给客户端提供一个统一的抽象目录树，客户端通过路径来访问文件，形如：hdfs://host:port/xxx/xxx/file.data</p>
</li>
<li><p>目录结构及文件分块信息(元数据)的管理由namenode节点承担<br>——namenode是HDFS集群主节点，负责维护整个hdfs文件系统的目录树，以及每一个路径（文件）所对应的block块信息（block的id，及所在的datanode服务器）</p>
</li>
<li><p>文件的各个block的存储管理由datanode节点承担<br>—- datanode是HDFS集群从节点，每一个block都可以在多个datanode上存储多个副本（副本数量也可以通过参数设置dfs.replication）</p>
</li>
<li><p>HDFS是设计成适应一次写入，多次读出的场景，且不支持文件的修改</p>
</li>
</ul>
</li>
</ul>
<p><strong>(注：适合用来做数据分析，并不适合用来做网盘应用，因为，不便修改，延迟大，网络开销大，成本太高)</strong></p>
<h3 id="HDFS常用命令"><a href="#HDFS常用命令" class="headerlink" title="HDFS常用命令"></a>HDFS常用命令</h3><pre><code>* dfs == hadoop fs
* dfs -mkdir /xxx              //在hdfs上创建目录
* dfs -ls -r /xxx              //显示目录信息
* dfs -lsr  /xxx          //递归查看HDFS目录文件
* dfs -put a.html /xxx    //等同于copyFromLocal
* dfs -get /xxx/a.html    //等同于copyToLocal，就是从hdfs下载文件到本地
* dfs -rm -r -f /data     //删除文件夹下所有文件
* dfs -cat    /xxx/a.txt      //显示文件内容
* dfs -moveFromLocal         //从本地剪切粘贴到hdfs
* dfs -moveToLocal             //从hdfs剪切粘贴到本地
* dfs -appendToFile         //追加一个文件到已经存在的文件末尾
* dfs -tail               //显示一个文件的末尾
* dfs -cp                          //从hdfs的一个路径拷贝hdfs的另一个路径
* dfs -mv                          //从hdfs的一个路径拷贝hdfs的另一个路径
* dfs -rm                          //删除文件或文件夹
* version 
</code></pre><h3 id="HSFS原理"><a href="#HSFS原理" class="headerlink" title="HSFS原理"></a>HSFS原理</h3><ul>
<li><p>hdfs工作机制</p>
<p>（工作机制的学习主要是为加深对分布式系统的理解，以及增强遇到各种问题时的分析解决能力，形成一定的集群运维能力）</p>
<p>  注：很多不是真正理解hadoop技术体系的人会常常觉得HDFS可用于网盘类应用，但实际并非如此。要想将技术准确用在恰当的地方，必须对技术有深刻的理解</p>
</li>
<li><p>概述</p>
<ul>
<li>HDFS集群分为两大角色：NameNode、DataNode  (Secondary Namenode)</li>
<li>NameNode负责管理整个文件系统的元数据</li>
<li>DataNode 负责管理用户的文件数据块</li>
<li>文件会按照固定的大小（blocksize）切成若干块后分布式存储在若干台datanode上</li>
<li>每一个文件块可以有多个副本，并存放在不同的datanode上</li>
<li>Datanode会定期向Namenode汇报自身所保存的文件block信息，而namenode则会负责保持文件的副本数量</li>
<li>HDFS的内部工作机制对客户端保持透明，客户端请求访问HDFS都是通过向namenode申请来进行</li>
</ul>
</li>
</ul>
<ul>
<li><p>HDFS上传文件的步骤</p>
<p>客户端要向HDFS写数据，首先要跟namenode通信以确认可以写文件并获得接收文件block的datanode，然后，客户端按顺序将文件逐个block传递给相应datanode，并由接收到block的datanode负责向其他datanode复制block的副本</p>
<ul>
<li>根namenode通信请求上传文件，namenode检查目标文件是否已存在，父目录是否存在</li>
<li>namenode返回是否可以上传</li>
<li>client请求第一个 block该传输到哪些datanode服务器上</li>
<li>namenode返回3个datanode服务器ABC</li>
<li>client请求3台dn中的一台A上传数据（本质上是一个RPC调用，建立pipeline），A收到请求会继续调</li>
<li>然后B调用C，将真个pipeline建立完成，逐级返回客户端</li>
<li>client开始往A上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，A收到一个packet就会传给B，B传给C；A每传一个packet会放入一个应答队列等待应答</li>
<li>当一个block传输完成之后，client再次请求namenode上传第二个block的服务器。</li>
</ul>
</li>
</ul>
<ul>
<li><p>HDFS 读数据流程</p>
<p>客户端将要读取的文件路径发送给namenode，namenode获取文件的元信息（主要是block的存放位置信息）返回给客户端，客户端根据返回的信息找到相应datanode逐个获取文件的block并在客户端本地进行数据追加合并从而获得整个文件</p>
<ul>
<li>跟namenode通信查询元数据，找到文件块所在的datanode服务器</li>
<li>挑选一台datanode（就近原则，然后随机）服务器，请求建立socket流</li>
<li>datanode开始发送数据（从磁盘里面读取数据放入流，以packet为单位来做校验）</li>
<li>客户端以packet为单位接收，现在本地缓存，然后写入目标文件</li>
</ul>
</li>
</ul>
<h3 id="namenode工作机制"><a href="#namenode工作机制" class="headerlink" title="namenode工作机制"></a>namenode工作机制</h3><h4 id="namenode职责"><a href="#namenode职责" class="headerlink" title="namenode职责"></a>namenode职责</h4><blockquote>
<p>负责客户端请求的响应，元数据的管理（查询，修改）</p>
</blockquote>
<h4 id="元数据管理"><a href="#元数据管理" class="headerlink" title="元数据管理"></a>元数据管理</h4><p>namenode对数据的管理采用了三种存储形式：</p>
<ul>
<li>内存元数据(NameSystem)</li>
<li>磁盘元数据镜像文件</li>
<li>数据操作日志文件（可通过日志运算出元数据）</li>
</ul>
<h5 id="元数据存储机制"><a href="#元数据存储机制" class="headerlink" title="元数据存储机制"></a>元数据存储机制</h5><ul>
<li><p>内存中有一份完整的元数据(<strong>内存meta data</strong>)</p>
</li>
<li><p>磁盘有一个“准完整”的元数据镜像（<strong>fsimage</strong>）文件(在namenode的工作目录中</p>
</li>
<li><p>用于衔接内存metadata和持久化元数据镜像fsimage之间的操作日志（edits文件）</p>
</li>
</ul>
<p><strong>注：当客户端对hdfs中的文件进行新增或者修改操作，操作记录首先被记入edits日志文件中，当客户端操作成功后，相应的元数据会更新到内存meta.data中</strong></p>
<h5 id="元数据手动查看"><a href="#元数据手动查看" class="headerlink" title="元数据手动查看"></a>元数据手动查看</h5><ul>
<li>可以通过hdfs的一个工具来查看edits中的信息</li>
<li>bin/hdfs oev -i edits -o edits.xml</li>
<li>bin/hdfs oiv -i fsimage_0000000000000000087 -p XML -o fsimage.xml</li>
</ul>
<h5 id="元数据的checkpoint"><a href="#元数据的checkpoint" class="headerlink" title="元数据的checkpoint"></a>元数据的checkpoint</h5><p>每隔一段时间，会由secondary namenode将namenode上积累的所有edits和一个最新的fsimage下载到本地，并加载到内存进行merge（这个过程称为checkpoint）</p>
<h5 id="元数据目录说明"><a href="#元数据目录说明" class="headerlink" title="元数据目录说明"></a>元数据目录说明</h5><p>在第一次部署好Hadoop集群的时候，我们需要在NameNode（NN）节点上格式化磁盘：</p>
<p>   $HADOOP_HOME/bin/hdfs   namenode -format   </p>
<p>格式化完成之后，将会在$dfs.namenode.name.dir/current目录下如下的文件结构</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">current/</span><br><span class="line">|-- VERSION</span><br><span class="line">|-- edits_*</span><br><span class="line">|-- fsimage_0000000000008547077</span><br><span class="line">|-- fsimage_0000000000008547077.md5</span><br><span class="line">|-- seen_txid</span><br></pre></td></tr></table></figure>
<p>其中的dfs.name.dir是在hdfs-site.xml文件中配置的，默认值如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.name.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;file://$&#123;hadoop.tmp.dir&#125;/dfs/name&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">hadoop.tmp.dir是在core-site.xml中配置的，默认值如下</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/tmp/hadoop-$&#123;user.name&#125;&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;A base for other temporary directories.&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<p>dfs.namenode.name.dir属性可以配置多个目录，</p>
<p>如/data1/dfs/name,/data2/dfs/name,/data3/dfs/name,….。各个目录存储的文件结构和内容都完全一样，相当于备份，这样做的好处是当其中一个目录损坏了，也不会影响到Hadoop的元数据，特别是当其中一个目录是NFS（网络文件系统Network File System，NFS）之上，即使你这台机器损坏了，元数据也得到保存。<br> 下面对$dfs.namenode.name.dir/current/目录下的文件进行解释。<br> 1、VERSION文件是Java属性文件，内容大致如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#Fri Nov 15 19:47:46 CST 2013</span><br><span class="line">namespaceID=934548976</span><br><span class="line">clusterID=CID-cdff7d73-93cd-4783-9399-0a22e6dce196</span><br><span class="line">cTime=0</span><br><span class="line">storageType=NAME_NODE</span><br><span class="line">blockpoolID=BP-893790215-192.168.24.72-1383809616115</span><br><span class="line">layoutVersion=-47</span><br></pre></td></tr></table></figure>
<p>其中<br> 　　(1).namespaceID是文件系统的唯一标识符，在文件系统首次格式化之后生成的；<br> 　　(2).storageType说明这个文件存储的是什么进程的数据结构信息（如果是DataNode，storageType=DATA_NODE）；<br> 　　(3).cTime表示NameNode存储时间的创建时间，由于我的NameNode没有更新过，所以这里的记录值为0，以后对NameNode升级之后，cTime将会记录更新时间戳；<br> 　　(4).layoutVersion表示HDFS永久性数据结构的版本信息， 只要数据结构变更，版本号也要递减，此时的HDFS也需要升级，否则磁盘仍旧是使用旧版本的数据结构，这会导致新版本的NameNode无法使用；<br> 　　(5).clusterID是系统生成或手动指定的集群ID，在-clusterid选项中可以使用它；如下说明</p>
<p>​    a、使用如下命令格式化一个Namenode：</p>
<p>​    <code>$HADOOP_HOME/bin/hdfs namenode -format [-clusterId &lt;cluster_id&gt;]</code></p>
<p>​    选择一个唯一的cluster_id，并且这个cluster_id不能与环境中其他集群有冲突。如果没有提供cluster_id，则会自动生成一个唯一的ClusterID。</p>
<p>​    b、使用如下命令格式化其他Namenode：</p>
<pre><code>`$HADOOP_HOME/bin/hdfs namenode -format -clusterId &lt;cluster_id&gt;`
</code></pre><p>​    c、升级集群至最新版本。在升级过程中需要提供一个ClusterID，例如：</p>
<p>​    <code>$HADOOP_PREFIX_HOME/bin/hdfs start namenode --config $HADOOP_CONF_DIR  -upgrade -clusterId &lt;cluster_ID&gt;</code></p>
<p>​    如果没有提供ClusterID，则会自动生成一个ClusterID。</p>
<p>​    (6).blockpoolID：是针对每一个Namespace所对应的blockpool的ID，上面的这个BP-893790215-192.168.24.72-1383809616115就是在我的ns1的namespace下的存储块池的ID，这个ID包括了其对应的NameNode节点的ip地址。</p>
<p>2、$dfs.namenode.name.dir/current/seen_txid非常重要，是存放transactionId的文件，format之后是0，它代表的是namenode里面的edits_*文件的尾数，namenode重启的时候，会按照seen_txid的数字，循序从头跑edits_0000001~到seen_txid的数字。所以当你的hdfs发生异常重启的时候，一定要比对seen_txid内的数字是不是你edits最后的尾数，不然会发生建置namenode时metaData的资料有缺少，导致误删Datanode上多余Block的资讯。</p>
<p>3、$dfs.namenode.name.dir/current目录下在format的同时也会生成fsimage和edits文件，及其对应的md5校验文件。</p>
<p>补充：seen_txid </p>
<p>文件中记录的是edits滚动的序号，每次重启namenode时，namenode就知道要将哪些edits进行加载edits</p>
<h3 id="DATANODE的工作机制"><a href="#DATANODE的工作机制" class="headerlink" title="DATANODE的工作机制"></a>DATANODE的工作机制</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><ul>
<li><p>Datanode工作职责：<br>存储管理用户的文件块数据<br>定期向namenode汇报自身所持有的block信息（通过心跳信息上报）<br>（这点很重要，因为，当集群中发生某些block副本失效时，集群如何恢复block初始副本数量的问题）</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.blockreport.intervalMsec&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;3600000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Datanode掉线判断时限参数<br>datanode进程死亡或者网络故障造成datanode无法与namenode通信，namenode不会立即把该节点判定为死亡，要经过一段时间，这段时间暂称作超时时长。HDFS默认的超时时长为10分钟+30秒。如果定义超时时间为timeout，则超时时长的计算公式为：<br><code>timeout  = 2 * heartbeat.recheck.interval + 10 * dfs.heartbeat.interval。</code></p>
<p>  而默认的heartbeat.recheck.interval 大小为5分钟，dfs.heartbeat.interval默认为3秒。<br>  需要注意的是hdfs-site.xml 配置文件中的heartbeat.recheck.interval的单位为毫秒，dfs.heartbeat.interval的单位为秒。所以，举个例子，如果heartbeat.recheck.interval设置为5000（毫秒），dfs.heartbeat.interval设置为3（秒，默认），则总的超时时间为40秒。</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;heartbeat.recheck.interval&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;2000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.heartbeat.interval&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="验证DATANODE功能"><a href="#验证DATANODE功能" class="headerlink" title="验证DATANODE功能"></a>验证DATANODE功能</h4><ul>
<li>上传一个文件，观察文件的block具体的物理存放情况：</li>
</ul>
<p>在每一台datanode机器上的这个目录中能找到文件的切块：<br>/home/hadoop/app/hadoop-2.4.1/tmp/dfs/data/current/BP-193442119-192.168.2.120-1432457733977/current/finalized</p>
<h3 id="hadoop-java客户端"><a href="#hadoop-java客户端" class="headerlink" title="hadoop java客户端"></a>hadoop java客户端</h3>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/02/04/hadoop/" data-id="cjrqbftz70013akc4vfk82y80" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-git-commit-standard" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/02/04/git-commit-standard/" class="article-date">
  <time datetime="2019-02-04T12:16:13.857Z" itemprop="datePublished">2019-02-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>title: git<br>date: 2018-03-05 11:31:12<br>tags: [linux, 后端, git]<br>categories: git</p>
<h1 id="git-提交规范"><a href="#git-提交规范" class="headerlink" title="git 提交规范"></a>git 提交规范</h1><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a><strong>前言</strong></h3><p>无规矩不成方圆，编程也一样。</p>
<p>如果你有一个项目，从始至终都是自己写，那么你想怎么写都可以，没有人可以干预你。可是如果在团队协作中，大家都张扬个性，那么代码将会是一团糟，好好的项目就被糟践了。不管是开发还是日后维护，都将是灾难。</p>
<h3 id="提交规则"><a href="#提交规则" class="headerlink" title="提交规则"></a><strong>提交规则</strong></h3><p>一个commit只做一件事情，若一个commit做了多件事情需要拆分成多个commit<br>严格遵循commit message格式<br>每次只允许提交一个commit，若本地有多个commit等待提交，必须等前面的commit合并进入主版本库并在本地合并完成后才可提交后面的commit</p>
<h3 id="内容要求"><a href="#内容要求" class="headerlink" title="内容要求"></a><strong>内容要求</strong></h3><p>在commit log中，要写清楚以下几点内容：</p>
<p>这个commit解决了哪个问题，或者实现了哪个功能，需要有对应的bug url或者功能列表url；<br>如果是个bug fix，请详述之前存在什么问题，这个commit是如何解决的；<br>如果这个commit只是一个大的过程中的某一步，请注明，并且简要列出这个commit之后还需要做的事情；<br>如果有需要提醒审核者注意的问题，比如一个known bug，或者还有某些已知问题，或者需要未来重构，请用“NOTICE：”另起一行标注并说明。</p>
<h3 id="提交格式"><a href="#提交格式" class="headerlink" title="提交格式"></a><strong>提交格式</strong></h3><p>Git Commit 规范可能并没有那么夸张，但如果你在版本回退的时候看到一大段糟心的 Commit，恐怕会懊恼不已吧。所以，严格遵守规范，利人利己，建议大家养成良好的开发习惯。<br>每次提交，Commit message 都包括三个部分：header，body 和 footer。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;</span><br><span class="line">&lt;BLANK LINE&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;BLANK LINE&gt;</span><br><span class="line">&lt;footer&gt;</span><br></pre></td></tr></table></figure>
<p>其中，header 是必需的，body 和 footer 可以省略。<br>不管是哪一个部分，任何一行都不得超过72个字符（或100个字符）。这是为了避免自动换行影响美观。</p>
<p><strong>Header</strong></p>
<p>Header部分只有一行，包括三个字段：type（必需）、scope（可选）和subject（必需）。</p>
<p><strong>type</strong></p>
<p>用于说明 commit 的类别，只允许使用下面7个标识。</p>
<ul>
<li>feat：新功能（feature）</li>
<li>fix：修补bug</li>
<li>docs：文档（documentation）</li>
<li>style： 格式（不影响代码运行的变动）</li>
<li>refactor：重构（即不是新增功能，也不是修改bug的代码变动）</li>
<li>test：增加测试</li>
<li>chore：构建过程或辅助工具的变动</li>
</ul>
<p>如果type为feat和fix，则该 commit 将肯定出现在 Change log 之中。其他情况（docs、chore、style、refactor、test）由你决定，要不要放入 Change log，建议是不要。</p>
<p><strong>scope</strong></p>
<p>scope用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。</p>
<p>如果你的修改影响了不止一个scope，你可以使用*代替。</p>
<p><strong>subject</strong></p>
<p>subject是 commit 目的的简短描述，不超过50个字符。</p>
<p><strong>其他注意事项：</strong></p>
<ul>
<li>以动词开头，使用第一人称现在时，比如change，而不是changed或changes</li>
<li>第一个字母小写</li>
<li>结尾不加句号（.）</li>
</ul>
<p><strong>Body</strong></p>
<p>Body 部分是对本次 commit 的详细描述，可以分成多行。下面是一个范例。</p>
<p>More detailed explanatory text, if necessary.  Wrap it to<br>about 72 characters or so. </p>
<p>Further paragraphs come after blank lines.</p>
<ul>
<li>Bullet points are okay, too</li>
<li>Use a hanging indent</li>
</ul>
<p><strong>有两个注意点:</strong></p>
<ul>
<li>使用第一人称现在时，比如使用change而不是changed或changes。</li>
<li>永远别忘了第2行是空行</li>
<li>应该说明代码变动的动机，以及与以前行为的对比。</li>
</ul>
<p><strong>Footer</strong></p>
<p>Footer 部分只用于以下两种情况：</p>
<ul>
<li>不兼容变动</li>
<li>如果当前代码与上一个版本不兼容，则 Footer 部分以BREAKING CHANGE开头，后面是对变动的描述、以及变动理由和迁移方法。</li>
</ul>
<p>create procedure product()<br>begin<br> declare i int;<br> set i=0;<br> while i&lt;5 do<br>  insert into t1(filed) values(i);<br>  set i=i+1;<br> end while;<br>end;</p>
<p>delimiter $                                                           </p>
<p>create procedure hello(in n int)<br>begin<br>declare num001 , num002 int;                                </p>
<p>set num001 = 1 , num002 = 10;                             </p>
<p>while n - num001 &gt;= 0 do<br>/<em>当num001小于等于n时执行下面的操作</em>/</p>
<p>insert into test(test_name,test_num)</p>
<p>values(concat(“zhangsan” , num001) , num002);<br>/<em>在test表中插入数据test_name=zhangsan+num001,test_num=num002，contat意为将张三和num001连起来</em>/</p>
<p>set num001=num001+1,num002=num002<em>2;<br>/</em>设置num001=num001+1,num002=num002<em>2</em>/</p>
<p>end while;<br>/<em>当num&gt;100时，不再执行插入操作循环结束</em>/</p>
<p>end $                                                                </p>
<p>delimiter ;  </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/02/04/git-commit-standard/" data-id="cjrqbftxv000eakc4kkzc1gdu" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Git-Commit-Message-Style-Guide" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/02/04/Git-Commit-Message-Style-Guide/" class="article-date">
  <time datetime="2019-02-04T12:16:13.832Z" itemprop="datePublished">2019-02-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>title: Git Commit Message StyleGuide<br>date: 2018-01-05 11:31:12<br>tags: [linux, 大数据, git]<br>categories: git</p>
<h1 id="Git-Commit-Message-StyleGuide"><a href="#Git-Commit-Message-StyleGuide" class="headerlink" title="Git Commit Message StyleGuide"></a>Git Commit Message StyleGuide</h1><h5 id="TOC"><a href="#TOC" class="headerlink" title="TOC"></a>TOC</h5><ul>
<li><a href="#about">About</a></li>
<li><a href="#commit-message-format">Commit Message Format</a></li>
<li><a href="#suggested-emojis">Suggested Emojis</a></li>
<li><a href="#tools">Tools</a></li>
<li><a href="#references">References</a></li>
<li><a href="#fun-emoji-usages">Fun Emoji Usages</a></li>
<li><a href="#contributing">Contributing</a></li>
<li><a href="#license">License</a></li>
</ul>
<h2 id="About"><a href="#About" class="headerlink" title="About"></a>About</h2><p>This is an attempt to standardize the format of commit messages, for the sake of <strong>uniformity</strong> in git log, <strong>best practices</strong> for writing commit messages &amp; <strong>fun</strong>!</p>
<p>Using emojis at the beginning of commit messages, other than being fun, provides a simple way to indicate the intention of that commit, an ease for the eyes when browsing/reviewing git log. It’s also a simple measure of the fact that how much that commit is focused on a single purpose, which is a good practice.</p>
<p>If these rules and/or using emojis is an <a href="/../../issues/21">overkill</a> for your productivity or simply losing its purposes, please tailor them to your needs or don’t use them.</p>
<h3 id="Summary-of-the-reasons-for-these-conventions"><a href="#Summary-of-the-reasons-for-these-conventions" class="headerlink" title="Summary of the reasons for these conventions:"></a>Summary of the reasons for these conventions:</h3><ul>
<li>Fun!</li>
<li>Simple navigation through git history (e.g. ignoring style changes).</li>
<li>Automatic generating of the changelog.</li>
</ul>
<h2 id="Commit-Message-Format"><a href="#Commit-Message-Format" class="headerlink" title="Commit Message Format"></a>Commit Message Format</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;</span><br><span class="line"></span><br><span class="line">&lt;body&gt;</span><br><span class="line"></span><br><span class="line">&lt;footer&gt;</span><br></pre></td></tr></table></figure>
<h3 id="Message-Subject-first-line"><a href="#Message-Subject-first-line" class="headerlink" title="Message Subject(first line)"></a>Message Subject(first line)</h3><ul>
<li>Capitalize the <code>&lt;subject&gt;</code>.</li>
<li>Do not end the first line with a period.</li>
<li>Total characters of the first line <strong>MUST</strong> be <em>Less</em> than or <em>Equal</em> to <strong>50</strong> characters Long.</li>
<li>Use the <strong>present tense</strong> (“Add feature” not “Added feature”).</li>
<li>Use the <strong>imperative mood</strong> (“Move cursor to…” not “Moves cursor to…”).</li>
<li>Use <code>&lt;type&gt;</code> to identify what type of changes introduced in this commit; Allowed <code>&lt;type&gt;</code> keywords:<ul>
<li>An Emoji(see below for <a href="#suggested-emojis">list of Suggested Emojis</a>)</li>
<li>Or a Text:<ul>
<li>feat: new feature for the user(or :sparkles: emoji)</li>
<li>fix: bug fix for the user(or :ambulance: emoji)</li>
<li>docs: changes to the documentation(or :books: emoji)</li>
<li>style: formatting, missing semi colons, etc; no production code change(or :art: emoji)</li>
<li>refactor: refactoring production code, eg. renaming a variable(or :tractor: emoji)</li>
<li>test: adding missing tests, refactoring tests; no production code change(or :microscope: emoji)</li>
<li>chore: updating grunt tasks etc; no production code change</li>
</ul>
</li>
</ul>
</li>
<li>If you need more than one keyword or emoji to use, you should probably think twice!. This usally means you need to break this commit into more smaller commits; If thats not the case then separate each emoji with a space.</li>
<li>Use <code>&lt;scope&gt;</code> to identify which component this <code>&lt;type&gt;</code> is related to; Example <code>&lt;scope&gt;</code> values:<ul>
<li>init</li>
<li>runner</li>
<li>watcher</li>
<li>config</li>
<li>web-server</li>
<li>proxy</li>
<li>etc.</li>
</ul>
</li>
<li>The <code>&lt;scope&gt;</code> can also be empty (e.g. if the change is a global or difficult to assign to a single component), in which case the parentheses are omitted.</li>
</ul>
<h3 id="Message-Body"><a href="#Message-Body" class="headerlink" title="Message Body"></a>Message Body</h3><ul>
<li>Includes <strong>motivation</strong> for the change and contrasts with previous behavior.</li>
<li>Use the body to explain <strong>whats</strong> and <strong>whys</strong> vs. <em>hows</em>.</li>
<li>Wrap each line of the body at <strong>72</strong> characters.</li>
</ul>
<h3 id="Message-Footer"><a href="#Message-Footer" class="headerlink" title="Message Footer"></a>Message Footer</h3><ul>
<li>Reference issues this commit is related to with the status of that Issue; Ex. <code>Issue #27</code>, <code>Ref T27</code> or <code>Ref T27, T56</code> or <code>Fixes T8</code>.</li>
<li>Supported issue tracker status keywords:<ul>
<li>Fixes</li>
<li>Fixed</li>
<li>Closes</li>
<li>Closed</li>
<li>Resolves</li>
<li>Resolved</li>
<li>Ref</li>
<li>Issue</li>
<li>Issues</li>
</ul>
</li>
<li>More info on issue tracker status keywords:<ul>
<li><a href="https://help.github.com/articles/closing-issues-using-keywords/" target="_blank" rel="noopener">GitHub Issues</a></li>
<li><a href="https://docs.gitlab.com/ee/user/project/issues/automatic_issue_closing.html" target="_blank" rel="noopener">GitLab Issues</a></li>
<li><a href="https://secure.phabricator.com/book/phabricator/article/diffusion_autoclose/" target="_blank" rel="noopener">Phabricator Tasks</a></li>
</ul>
</li>
<li>It’s also <a href="/../../issues/19">recommended</a> to use <em>Full URL to the Issues</em>, instead of just issue ID Number; Doing so will ease browsing issues from terminal.</li>
<li>In the case of multiple issues separate them with commas, Ex. <code>Closes #27, #56</code>.</li>
</ul>
<h3 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h3><ul>
<li>Use valid <a href="https://daringfireball.net/projects/markdown/basics" target="_blank" rel="noopener">MarkDown</a> format in the <code>&lt;body&gt;</code>.</li>
<li>All <strong>WIP</strong>(Work In Progress) commits <strong>SHOULD</strong> have the :construction: Emoji.</li>
<li>All <strong>WIP</strong> commits <strong>SHOULD</strong> be avoided!.</li>
<li>Referencing Issues by using special keywords like <code>Fixes</code> or <code>Resolves</code> will mark them as closed automatically! For more  information about automatic issue closing using ketwords see their documentation(linked above).</li>
<li>There is <strong>NO</strong> new-line after the <code>&lt;footer&gt;</code>.</li>
<li>Every emoji text(<code>:emoji:</code>) is counted as one character!.</li>
<li>See <a href="https://github.com/slashsbin/styleguide-todo-grammar" target="_blank" rel="noopener">ToDo Grammar StyleGuide</a> for more Information on <code>@XXX</code> Comment Tags.</li>
</ul>
<h2 id="Suggested-Emojis"><a href="#Suggested-Emojis" class="headerlink" title="Suggested Emojis"></a>Suggested Emojis</h2><table>
<thead>
<tr>
<th style="text-align:center">Emoji</th>
<th style="text-align:center">Raw Emoji Code</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">:art:</td>
<td style="text-align:center"><code>:art:</code></td>
<td>when improving the <strong>format</strong>/structure of the code</td>
</tr>
<tr>
<td style="text-align:center">:newspaper:</td>
<td style="text-align:center"><code>:newspaper:</code></td>
<td>when creating a <strong>new file</strong></td>
</tr>
<tr>
<td style="text-align:center">:pencil:</td>
<td style="text-align:center"><code>:pencil:</code></td>
<td>when <strong>performing minor changes/fixing</strong> the code or language</td>
</tr>
<tr>
<td style="text-align:center">:racehorse:</td>
<td style="text-align:center"><code>:racehorse:</code></td>
<td>when improving <strong>performance</strong></td>
</tr>
<tr>
<td style="text-align:center">:books:</td>
<td style="text-align:center"><code>:books:</code></td>
<td>when writing <strong>docs</strong></td>
</tr>
<tr>
<td style="text-align:center">:bug:</td>
<td style="text-align:center"><code>:bug:</code></td>
<td>when reporting a <strong>bug</strong>, with <a href="https://github.com/slashsbin/styleguide-todo-grammar#bug-report" target="_blank" rel="noopener"><code>@FIXME</code></a>Comment Tag</td>
</tr>
<tr>
<td style="text-align:center">:ambulance:</td>
<td style="text-align:center"><code>:ambulance:</code></td>
<td>when fixing a <strong>bug</strong></td>
</tr>
<tr>
<td style="text-align:center">:penguin:</td>
<td style="text-align:center"><code>:penguin:</code></td>
<td>when fixing something on <strong>Linux</strong></td>
</tr>
<tr>
<td style="text-align:center">:apple:</td>
<td style="text-align:center"><code>:apple:</code></td>
<td>when fixing something on <strong>Mac OS</strong></td>
</tr>
<tr>
<td style="text-align:center">:checkered_flag:</td>
<td style="text-align:center"><code>:checkered_flag:</code></td>
<td>when fixing something on <strong>Windows</strong></td>
</tr>
<tr>
<td style="text-align:center">:fire:</td>
<td style="text-align:center"><code>:fire:</code></td>
<td>when <strong>removing code</strong> or files, <em>maybe</em> with <code>@CHANGED</code> Comment Tag</td>
</tr>
<tr>
<td style="text-align:center">:tractor:</td>
<td style="text-align:center"><code>:tractor:</code></td>
<td>when <strong>change file structure</strong>. Usually together with :art:</td>
</tr>
<tr>
<td style="text-align:center">:hammer:</td>
<td style="text-align:center"><code>:hammer:</code></td>
<td>when <strong>refactoring</strong> code</td>
</tr>
<tr>
<td style="text-align:center">:umbrella:</td>
<td style="text-align:center"><code>:umbrella:</code></td>
<td>when adding <strong>tests</strong></td>
</tr>
<tr>
<td style="text-align:center">:microscope:</td>
<td style="text-align:center"><code>:microscope:</code></td>
<td>when adding <strong>code coverage</strong></td>
</tr>
<tr>
<td style="text-align:center">:green_heart:</td>
<td style="text-align:center"><code>:green_heart:</code></td>
<td>when fixing the <strong>CI</strong> build</td>
</tr>
<tr>
<td style="text-align:center">:lock:</td>
<td style="text-align:center"><code>:lock:</code></td>
<td>when dealing with <strong>security</strong></td>
</tr>
<tr>
<td style="text-align:center">:arrow_up:</td>
<td style="text-align:center"><code>:arrow_up:</code></td>
<td>when upgrading <strong>dependencies</strong></td>
</tr>
<tr>
<td style="text-align:center">:arrow_down:</td>
<td style="text-align:center"><code>:arrow_down:</code></td>
<td>when downgrading <strong>dependencies</strong></td>
</tr>
<tr>
<td style="text-align:center">:fast_forward:</td>
<td style="text-align:center"><code>:fast_forward:</code></td>
<td>when <strong>forward-porting features</strong> from an older version/branch</td>
</tr>
<tr>
<td style="text-align:center">:rewind:</td>
<td style="text-align:center"><code>:rewind:</code></td>
<td>when <strong>backporting features</strong> from a newer version/branch</td>
</tr>
<tr>
<td style="text-align:center">:shirt:</td>
<td style="text-align:center"><code>:shirt:</code></td>
<td>when removing <strong>linter</strong>/strict/deprecation warnings</td>
</tr>
<tr>
<td style="text-align:center">:lipstick:</td>
<td style="text-align:center"><code>:lipstick:</code></td>
<td>when improving <strong>UI</strong>/Cosmetic</td>
</tr>
<tr>
<td style="text-align:center">:wheelchair:</td>
<td style="text-align:center"><code>:wheelchair:</code></td>
<td>when improving <strong>accessibility</strong></td>
</tr>
<tr>
<td style="text-align:center">:globe_with_meridians:</td>
<td style="text-align:center"><code>:globe_with_meridians:</code></td>
<td>when dealing with <strong>globalization</strong>/internationalization/i18n/g11n</td>
</tr>
<tr>
<td style="text-align:center">:construction:</td>
<td style="text-align:center"><code>:construction:</code></td>
<td><strong>WIP</strong>(Work In Progress) Commits, <em>maybe</em> with <code>@REVIEW</code> Comment Tag</td>
</tr>
<tr>
<td style="text-align:center">:gem:</td>
<td style="text-align:center"><code>:gem:</code></td>
<td>New <strong>Release</strong></td>
</tr>
<tr>
<td style="text-align:center">:egg:</td>
<td style="text-align:center"><code>:egg:</code></td>
<td>New <strong>Release</strong> with Python egg</td>
</tr>
<tr>
<td style="text-align:center">:ferris_wheel:</td>
<td style="text-align:center"><code>:ferris_wheel:</code></td>
<td>New <strong>Release</strong> with Python wheel package</td>
</tr>
<tr>
<td style="text-align:center">:bookmark:</td>
<td style="text-align:center"><code>:bookmark:</code></td>
<td>Version <strong>Tags</strong></td>
</tr>
<tr>
<td style="text-align:center">:tada:</td>
<td style="text-align:center"><code>:tada:</code></td>
<td><strong>Initial</strong> Commit</td>
</tr>
<tr>
<td style="text-align:center">:speaker:</td>
<td style="text-align:center"><code>:speaker:</code></td>
<td>when Adding <strong>Logging</strong></td>
</tr>
<tr>
<td style="text-align:center">:mute:</td>
<td style="text-align:center"><code>:mute:</code></td>
<td>when Reducing <strong>Logging</strong></td>
</tr>
<tr>
<td style="text-align:center">:sparkles:</td>
<td style="text-align:center"><code>:sparkles:</code></td>
<td>when introducing <strong>New</strong> Features</td>
</tr>
<tr>
<td style="text-align:center">:zap:</td>
<td style="text-align:center"><code>:zap:</code></td>
<td>when introducing <strong>Backward-InCompatible</strong> Features, <em>maybe</em> with <code>@CHANGED</code> Comment Tag</td>
</tr>
<tr>
<td style="text-align:center">:bulb:</td>
<td style="text-align:center"><code>:bulb:</code></td>
<td>New <strong>Idea</strong>, with <code>@IDEA</code> Comment Tag</td>
</tr>
<tr>
<td style="text-align:center">:snowflake:</td>
<td style="text-align:center"><code>:snowflake:</code></td>
<td>changing <strong>Configuration</strong>, Usually together with :penguin: or :ribbon: or :rocket:</td>
</tr>
<tr>
<td style="text-align:center">:ribbon:</td>
<td style="text-align:center"><code>:ribbon:</code></td>
<td>Customer requested application <strong>Customization</strong>, with <code>@HACK</code> Comment Tag</td>
</tr>
<tr>
<td style="text-align:center">:rocket:</td>
<td style="text-align:center"><code>:rocket:</code></td>
<td>Anything related to Deployments/<strong>DevOps</strong></td>
</tr>
<tr>
<td style="text-align:center">:elephant:</td>
<td style="text-align:center"><code>:elephant:</code></td>
<td><strong>PostgreSQL</strong> Database specific (Migrations, Scripts, Extensions, …)</td>
</tr>
<tr>
<td style="text-align:center">:dolphin:</td>
<td style="text-align:center"><code>:dolphin:</code></td>
<td><strong>MySQL</strong> Database specific (Migrations, Scripts, Extensions, …)</td>
</tr>
<tr>
<td style="text-align:center">:leaves:</td>
<td style="text-align:center"><code>:leaves:</code></td>
<td><strong>MongoDB</strong> Database specific (Migrations, Scripts, Extensions, …)</td>
</tr>
<tr>
<td style="text-align:center">:bank:</td>
<td style="text-align:center"><code>:bank:</code></td>
<td><strong>Generic Database</strong> specific (Migrations, Scripts, Extensions, …)</td>
</tr>
<tr>
<td style="text-align:center">:whale:</td>
<td style="text-align:center"><code>:whale:</code></td>
<td><strong>Docker</strong> Configuration</td>
</tr>
<tr>
<td style="text-align:center">:handshake:</td>
<td style="text-align:center"><code>:handshake:</code></td>
<td>when <strong>Merge files</strong></td>
</tr>
<tr>
<td style="text-align:center">:cherries:</td>
<td style="text-align:center"><code>:cherries:</code></td>
<td>when Commit Arise from one or more <a href="https://git-scm.com/docs/git-cherry-pick" target="_blank" rel="noopener"><strong>Cherry-Pick</strong></a> Commit(s)</td>
</tr>
</tbody>
</table>
<h2 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h2><ul>
<li><a href="https://github.com/jakeasmith/commit" target="_blank" rel="noopener">Commit</a>(CLI): This is a nifty CLI tool to aid in standardizing commit messages based on this document, thanks to @jakeasmith.</li>
<li><a href="https://gitlab.com/louisgrasset/git-moji" target="_blank" rel="noopener">gitMoji</a>(Firefox &amp; Chrome Extension): Enhance your commits with emojis!, thanks to <a href="https://twitter.com/louisgrasset" target="_blank" rel="noopener">@louisgrasset</a>.</li>
</ul>
<h2 id="Fun-Emoji-Usages"><a href="#Fun-Emoji-Usages" class="headerlink" title="Fun Emoji Usages"></a>Fun Emoji Usages</h2><ul>
<li><a href="https://codemoji.org/" target="_blank" rel="noopener">CodeEmoji</a>: Mozilla’s Codemoji enciphers your messages with emoji for fun and profit</li>
<li><a href="https://blog.mozilla.org/services/2016/08/23/sending-vapid-identified-webpush-notifications-via-mozillas-push-service/#send_data" target="_blank" rel="noopener">Emoji Based Diagram</a>: Emoji Based Diagram of Data Bearing Subscription Updates(WebPush VAPID)</li>
</ul>
<h2 id="Contributing"><a href="#Contributing" class="headerlink" title="Contributing"></a>Contributing</h2><p><a href="https://github.com/slashsbin/styleguide-git-commit-message/issues/new" target="_blank" rel="noopener">Ask</a> to Be <a href="https://www.emojicopy.com/" target="_blank" rel="noopener">Creative</a>!</p>
<p>To add a new Emoji to the list: <a href="https://github.com/slashsbin/styleguide-git-commit-message/issues/new" target="_blank" rel="noopener">Create an Issue</a> &amp; Send a <a href="">PR</a>.</p>
<h2 id="License"><a href="#License" class="headerlink" title="License"></a>License</h2><p>The Code is licensed under the <a href="http://slashsbin.mit-license.org/" target="_blank" rel="noopener">MIT License</a>.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/02/04/Git-Commit-Message-Style-Guide/" data-id="cjrqbftyd000makc4m3fn0i3w" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Git" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/02/04/Git/" class="article-date">
  <time datetime="2019-02-04T12:16:13.804Z" itemprop="datePublished">2019-02-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>title: git<br>date: 2018-01-05 16:31:12<br>tags: [linux, 版本控制, git]<br>categories: git</p>
<h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><h2 id="git核心概念及"><a href="#git核心概念及" class="headerlink" title="git核心概念及"></a>git核心概念及</h2><h3 id="什么是git"><a href="#什么是git" class="headerlink" title="什么是git"></a>什么是git</h3><p>git是一个分布式版本控制软件，最初由林纳斯·托瓦兹创作，于2005年以GPL发布。最初目的是为更好地管理Linux内核开发而设计。应注意的是，这与GNU Interactive Tools（一个类似Norton Commander界面的文件管理器）有所不同。git最初的开发动力来自于BitKeeper和Monotone。git最初只是作为一个可以被其他前端（比如Cogito或Stgit）包装的后端而开发的，但后来git内核已经成熟到可以独立地用作版本控制。很多著名的软件都使用git进行版本控制，其中包括Linux内核、X.Org服务器和OLPC内核等项目的开发流程。</p>
<h3 id="版本控制系统"><a href="#版本控制系统" class="headerlink" title="版本控制系统"></a>版本控制系统</h3><p>Git 是目前世界上最优秀的分布式版本控制系统。版本控制系统是能够随着时间的推进记录一系列文件的变化以便于你以后想要的退回到某个版本的系统。版本控制系统分为三大类：本地版本控制系统，集中式版本控制系统和分布式版本控制系统</p>
<p>本地版本控制（Local Version Control Systems）是将文件的各个版本以一定的数据格式存储在本地的磁盘（有的VCS 是保存文件的变化补丁，即在文件内容变化时计算出差量保存起来），这种方式在一定程度上解决了手动复制粘贴的问题，但无法解决多人协作的问题。</p>
<p>集中式版本控制（Centralized Version Control Systems）相比本地版本控制没有什么本质的变化，只是多了个一个中央服务器，各个版本的数据库存储在中央服务器，管理员可以控制开发人员的权限，而开发人员也可以从中央服务器拉取数据。集中式版本控制虽然解决了团队协作问题，但缺点也很明显：所有数据存储在中央服务器，服务器一旦宕机或者磁盘损坏，会造成不可估量的损失。</p>
<p>分布式版本控制（ Distributed Version Control System）与前两者均不同。首先，在分布式版本控制系统中，像 Git，Mercurial，Bazaar 以及 Darcs 等，系统保存的的不是文件变化的差量，而是文件的快照，即把文件的整体复制下来保存，而不关心具体的变化内容。其次，最重要的是分布式版本控制系统是分布式的，当你从中央服务器拷贝下来代码时，你拷贝的是一个完整的版本库，包括历史纪录，提交记录等，这样即使某一台机器宕机也能找到文件的完整备份。</p>
<h3 id="Git-工作区、暂存区、版本库之间的关系"><a href="#Git-工作区、暂存区、版本库之间的关系" class="headerlink" title="Git 工作区、暂存区、版本库之间的关系"></a>Git 工作区、暂存区、版本库之间的关系</h3><p><strong>工作区(WorkingDirectory)</strong></p>
<p>工作目录是对项目的某个版本独立提取出来的内容。 这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘 上供你使用或修改。 </p>
<p><strong>暂存区(StagingArea)</strong></p>
<p>暂存区域是一个文件，保存了下次将提交的文件列表信息，一般在 Git 仓库目录中。 有时候也被称作`‘索 引’’，不过一般说法还是叫暂存区域。 </p>
<p><strong>版本库(Repository)</strong></p>
<p>Git 仓库目录是 Git 用来保存项目的元数据和对象数据库的地方。 这是 Git 中最重要的部分，从其它计算机克隆 仓库时，拷贝的就是这里的数据。 </p>
<h3 id="Git-工作流程"><a href="#Git-工作流程" class="headerlink" title="Git 工作流程"></a>Git 工作流程</h3><p>1.在工作目录中修改文件。<br>2.暂存文件，将文件的快照放入暂存区域。 3.提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。 </p>
<p>如果 Git 目录中保存着的特定版本文件，就属于已提交状态。 如果作了修改并已放入暂存区域，就属于已暂存状 态。 如果自上次取出后，作了修改但还没有放到暂存区域，就是已修改状态。 在Git 基础一章，你会进一步了解 这些状态的细节，并学会如何根据文件状态实施后续操作，以及怎样跳过暂存直接提交。 </p>
<h2 id="Git-常用命令详解"><a href="#Git-常用命令详解" class="headerlink" title="Git 常用命令详解"></a>Git 常用命令详解</h2><h3 id="1-Git文件操作"><a href="#1-Git文件操作" class="headerlink" title="1.Git文件操作"></a>1.Git文件操作</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">$ git help [command]                  # 显示command的help</span><br><span class="line">$ git show [$id]                      # 显示某次提交的内容 </span><br><span class="line">$ git checkout  [file]                # 抛弃工作区修改</span><br><span class="line">$ git checkout .                      # 抛弃工作区修改</span><br><span class="line">$ git add [file]                      # 将工作文件修改提交到本地暂存区</span><br><span class="line">$ git add .                           # 将所有修改过的工作文件提交暂存区</span><br><span class="line">$ git reset [file]                    # 从暂存区恢复到工作文件</span><br><span class="line">$ git reset -- .                      # 从暂存区恢复到工作文件</span><br><span class="line">$ git reset --mixed HEAD~1            # 修改版本库，修改暂存区，保留工作区</span><br><span class="line">$ git reset --soft HEAD~2             # 修改版本库，保留暂存区，保留工作区</span><br><span class="line">$ git reset --hard HEAD~3             # 修改版本库，修改暂存区，修改工作区</span><br><span class="line">$ git commit --amend                  # 修改最后一次提交记录</span><br><span class="line">$ git revert [$id]                    # 恢复某次提交的状态，恢复动作本身也创建次提交对象</span><br><span class="line">$ git revert HEAD                     # 恢复最后一次提交的状态</span><br><span class="line">$ git status                          # 查看当前工作区状态 </span><br><span class="line">$ git config --list                   # 看所有用户</span><br><span class="line">$ git ls-files                        # 查看已经被提交的文件</span><br><span class="line">$ git commit -a                       # 提交当前repos的所有的改变</span><br><span class="line">$ git commit -v                       # 参数-v可以查看看commit的差异</span><br><span class="line">$ git commit -m &quot;message&quot;             # 提交到本地并添加提交信息</span><br><span class="line">$ git commit -am &quot;init&quot;               # 添加并提交 </span><br><span class="line"></span><br><span class="line">$ git log 的常用选项 </span><br><span class="line"></span><br><span class="line">-p 按补丁格式显示每个更新之间的差异。 </span><br><span class="line">--stat 显示每次更新的文件修改统计信息。 </span><br><span class="line">--shortstat 只显示 --stat 中最后的行数修改添加移除统计。 </span><br><span class="line">--name-only 仅在提交信息后显示已修改的文件清单。 </span><br><span class="line">--name-status 显示新增、修改、删除的文件清单。 </span><br><span class="line">--abbrev-commit 仅显示 SHA-1 的前几个字符，而非所有的 40 个字符。 </span><br><span class="line">--relative-date 使用较短的相对时间显示（比如，“2 weeks ago”）。 </span><br><span class="line">--graph 显示 ASCII 图形表示的分支合并历史。 </span><br><span class="line">--pretty 使用其他格式显示历史提交</span><br><span class="line"></span><br><span class="line">$ git rm --cached [file]              # 从暂存区中删除文件</span><br><span class="line">$ git rm -f [file]                    # 强行移除版本控制的文件</span><br><span class="line">$ git rm -r --cached [file]           # 递归删除-r，是文件夹的时候有用</span><br><span class="line"></span><br><span class="line">$ git diff [file]                     # 比较当前文件和暂存区文件差异</span><br><span class="line">$ git diff [$id] [$id]                # 比较两次提交之间的差异</span><br><span class="line">$ git diff [branch1]..[branch2]       # 在两个分支之间比较</span><br><span class="line">$ git diff --staged                   # 比较暂存区和版本库差异</span><br><span class="line">$ git diff --cached                   # 比较暂存区和工作区差异</span><br><span class="line">$ git diff --stat                     # 仅仅比较统计信息</span><br><span class="line"></span><br><span class="line">$ git stash                           # 暂存当前正在进行的工作</span><br><span class="line">$ git stash push                      # 将暂存给push到一个临时空间中</span><br><span class="line">$ git stash list                      # 查看所有缓存的代码</span><br><span class="line">$ git stash clear                     # 清空缓存区内容</span><br><span class="line">$ git stash drop                      # 移除某个贮藏</span><br><span class="line">$ git stash save                      # 指定message</span><br><span class="line">$ git stash show                      # 查看指定stash的diff</span><br><span class="line">$ git stash apply stash@&#123;1&#125;           # 取出指定的缓存代码</span><br><span class="line">$ git stash pop                       # 将文件从临时空间pop下来</span><br><span class="line">$ git fetch origin dev:dev            # 获取最新版本到本地不会自动merge</span><br><span class="line">$ git pull origin master:master       # 获取最新版本到本地会自动merge</span><br></pre></td></tr></table></figure>
<h3 id="Git分支操作相关命令"><a href="#Git分支操作相关命令" class="headerlink" title="Git分支操作相关命令"></a>Git分支操作相关命令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ git branch                          # 查看分支</span><br><span class="line">$ git branch [dev] [master]           # 在master创建dev分支</span><br><span class="line">$ git branch -v                       # 查看各个分支最后提交信息</span><br><span class="line">$ git branch -r                       # 查看远程分支信息</span><br><span class="line">$ git branch -a                       # 查看所有分支信息</span><br><span class="line">$ git branch -m [aaa] [bbb]           # 将aaa 重命名为bbb</span><br><span class="line">$ git branch [name]                   # 从当前分支创建分支</span><br><span class="line">$ git branch -d [branch]              # 删除某个分支</span><br><span class="line">$ git branch -D [branch]              # 强制删除某个分支</span><br><span class="line">$ git branch --set-upstream-to origin/test master # 本地分支和远程分支关联</span><br><span class="line">$ git branch --set-upstream-to=origin/master help #</span><br><span class="line">$ git branch --merged                 # 查看已经被合并到当前分支的分支</span><br><span class="line">$ git branch --no-merged              # 查看尚未被合并到当前分支的分支</span><br><span class="line"></span><br><span class="line">$ git commit [$id] -b [new_branch]    # 从历史提交记录创建分支</span><br><span class="line">$ git commit [$id]                    # 从历史提交记录checkout出来，但无分支信息，切换到其他分支会自动删除</span><br><span class="line">$ git checkout [name]                 # 切换分支</span><br><span class="line">$ git checkout --track origin/dev     # 切换到远程dev分支</span><br><span class="line">$ git checkout -b [name]              # 从当前分支新建并切换到name</span><br><span class="line">$ git checkout -b [new_br] [br]       # 基于branch创建新的new_branch</span><br><span class="line">$ git merge origin/dev                # 将分支dev与当前分支进行合并</span><br><span class="line">$ git merge [branch]                  # 将branch分支合并到当前分支</span><br><span class="line">$ git merge origin/master --no-ff     # 不要Fast-Foward合并，这样可以生成merge提交</span><br><span class="line">$ git rebase master [branch]          # 将master rebase到branch，相当于： git clone [branch] &amp;&amp; git rebase master &amp;&amp; git clone master &amp;&amp; git merge [branch]</span><br></pre></td></tr></table></figure>
<h3 id="Git远程分支管理"><a href="#Git远程分支管理" class="headerlink" title="Git远程分支管理"></a>Git远程分支管理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">$ git pull                              # 抓取远程仓库所有分支更新并合并到本地</span><br><span class="line">$ git pull --no-ff                      # 抓取远程仓库所有分支更新并合并到本地，不要快进合并</span><br><span class="line">$ git fetch origin                      # 抓取远程仓库更新</span><br><span class="line">$ git merge origin/master               # 将远程主分支合并到本地当前分支</span><br><span class="line">$ git clone --track origin/branch       # 跟踪某个远程分支创建相应的本地分支</span><br><span class="line">$ git clone -b [l_b] origin/[r_b]       # 基于远程分支创建本地分支，功能同上</span><br><span class="line">$ git push                              # push所有分支</span><br><span class="line">$ git push origin master                # 将本地指定分支推到远程主分支</span><br><span class="line">$ git push -u origin master             # 将本地主分支推到远程(如无远程主分支则创建，用于初始化远程仓库)</span><br><span class="line">$ git clone [git@xxx.git]               # 克隆远程仓库</span><br><span class="line">$ git remote -v                         # 查看远程服务器地址和仓库名称</span><br><span class="line">$ git remote show [name]                # 查看远程服务器仓库状态</span><br><span class="line">$ git remote add [name] [url]           # 添加远程仓库地址</span><br><span class="line">$ git remote rm [repository]            # 删除远程仓库</span><br><span class="line">$ git remote set-url --push [name] [newUrl]# 修改远程仓库</span><br><span class="line">$ git pull [rName] [lName]              # 拉取远程分支</span><br><span class="line">$ git push [rName] [lName]              # 推送远程分支</span><br><span class="line">$ git push origin [lname]:[rname]       # 本地分支push到远程</span><br><span class="line">$ git push origin -d [name]             # 删除远程分支-d也可以用--delete</span><br><span class="line">$ git remote set-head origin master     # 设置远程仓库的HEAD指向master分支</span><br><span class="line">$ git branch --set-upstream master origin/master</span><br></pre></td></tr></table></figure>
<h3 id="Git版本回退操作相关命令"><a href="#Git版本回退操作相关命令" class="headerlink" title="Git版本回退操作相关命令"></a>Git版本回退操作相关命令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">HEAD ：当前版本</span><br><span class="line">HEAD^ ：上一个版本</span><br><span class="line">$ git log                               # 查看commit的信息</span><br><span class="line">$ git log --pretty=oneline              # 单行展示历史记录</span><br><span class="line">$ git log --oneline                     # 单行简单展示</span><br><span class="line">$ git reflog                            # 查看命令历史记录 </span><br><span class="line">$ git checkout .                        # 撤销所有本地改动代码</span><br><span class="line">$ git checkout [file]                   # 撤销所有本地改动代码</span><br><span class="line">$ git reset HEAD .                      # 撤销所有add文件 </span><br><span class="line">$ git reset HEAD [file]                 # 撤销单个add文件</span><br><span class="line">$ git reset --soft HEAD                 # 只回退commit的信息,保留修改代码</span><br><span class="line">$ git reset --hard HEAD^                # 彻底回退到上次commit版本,不保留修改代码</span><br><span class="line">$ git revert                            # 以前commit的id</span><br><span class="line">$ git reset --hard [branch]             # 本地代码回退到与git远程仓库保持一致</span><br><span class="line">--hard 参数会抛弃当前工作区的修改</span><br><span class="line">--soft 参数的话会回退到之前的版本，但是保留当前工作区的修改，可以重新提交</span><br></pre></td></tr></table></figure>
<h3 id="Git标签操作相关命令"><a href="#Git标签操作相关命令" class="headerlink" title="Git标签操作相关命令"></a>Git标签操作相关命令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ git tag                               # 查看标签</span><br><span class="line">$ git tag [name]                        # 创建版本</span><br><span class="line">$ git tag -d [name]                     # 删除版本</span><br><span class="line">$ git tag -r                            # 查看远程版本</span><br><span class="line">$ git push origin [name]                # 创建远程版本(本地版本push到远程)</span><br><span class="line">$ git push origin :refs/tags/[name]     # 删除远程版本</span><br><span class="line">$ git pull origin --tags                # 合并远程仓库的tag到本地</span><br><span class="line">$ git push origin --tags                # 上传本地tag到远程仓库</span><br><span class="line">$ git tag -a [name] -m [message]        # 创建带注释的tag</span><br></pre></td></tr></table></figure>
<h3 id="Git子模块-submodule-相关操作命令"><a href="#Git子模块-submodule-相关操作命令" class="headerlink" title="Git子模块(submodule)相关操作命令"></a>Git子模块(submodule)相关操作命令</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ git submodule add [url] [path]        # 添加子模块</span><br><span class="line">$ git submodule init                    # 初始化子模块，只在首次检出仓库时运行一次就行</span><br><span class="line">$ git submodule update                  # 更新子模块 每次更新或切换分支后都需要运行一下</span><br><span class="line">删除子模块：分4步</span><br><span class="line">1) $ git rm --cached [path]</span><br><span class="line">2) 编辑“.gitmodules”文件，将子模块的相关配置节点删除掉</span><br><span class="line">3) 编辑“ .git/config”文件，将子模块的相关配置节点删除掉</span><br><span class="line">4) 手动删除子模块残留的目录</span><br></pre></td></tr></table></figure>
<h3 id="Git补丁管理"><a href="#Git补丁管理" class="headerlink" title="Git补丁管理"></a>Git补丁管理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git diff ] ../sync.patch                # 生成补丁</span><br><span class="line">git apply ../sync.patch                 # 打补丁</span><br><span class="line">git apply --check ../sync.patch         #测试补丁能否成功</span><br></pre></td></tr></table></figure>
<h3 id="Git忽略一些文件、文件夹不提交"><a href="#Git忽略一些文件、文件夹不提交" class="headerlink" title="Git忽略一些文件、文件夹不提交"></a>Git忽略一些文件、文件夹不提交</h3><p>在仓库根目录下创建名称为“.gitignore”的文件，写入不需要的文件夹名或文件，每个元素占一行即可，如<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">target</span><br><span class="line">*.class</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>在工作中总结的一些常见的命令，今后还会继续补充，如有遗漏欢迎补充。</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/02/04/Git/" data-id="cjrqbftyc000lakc4pxez0oo2" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-flume" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/02/04/flume/" class="article-date">
  <time datetime="2019-02-04T12:16:13.791Z" itemprop="datePublished">2019-02-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>title: flume<br>date: 2018-01-05 11:31:12<br>tags: [linux, 大数据, flume]<br>categories: flume</p>
<h1 id="flume"><a href="#flume" class="headerlink" title="flume"></a>flume</h1><h2 id="flume-简介及核心概念"><a href="#flume-简介及核心概念" class="headerlink" title="flume 简介及核心概念"></a>flume 简介及核心概念</h2><h3 id="什么是flume"><a href="#什么是flume" class="headerlink" title="什么是flume"></a>什么是flume</h3><p>Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，目前是Apache的顶级项目。Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。</p>
<h3 id="flume-优点"><a href="#flume-优点" class="headerlink" title="flume 优点"></a>flume 优点</h3><p>1、可靠性<br>当节点出现故障时，日志能够被传送到其他节点上而不会丢失。Flume提供了三种级别的可靠性保障，从强到弱依次分别为：</p>
<ul>
<li>end-to-end（收到数据agent首先将event写到磁盘上，当数据传送成功后，再删除；如果数据发送失败，可以重新发送。），</li>
<li>Store on failure（这也是scribe采用的策略，当数据接收方crash时，将数据写到本地，待恢复后，继续发送），</li>
<li>Best effort（数据发送到接收方后，不会进行确认）。</li>
</ul>
<p>2、可扩展性<br>Flume采用了三层架构，分别为agent，collector和storage，每一层均可以水平扩展。<br>其中，所有agent和collector由master统一管理，这使得系统容易监控和维护，且master允许有多个（使用ZooKeeper进行管理和负载均衡），这就避免了单点故障问题。</p>
<p>3、可管理性</p>
<ul>
<li>所有agent和colletor由master统一管理，这使得系统便于维护。</li>
<li>多master情况，Flume利用ZooKeeper和gossip，保证动态配置数据的一致性。</li>
<li>用户可以在master上查看各个数据源或者数据流执行情况，且可以对各个数据源配置和动态加载。</li>
<li>Flume提供了web 和shell script command两种形式对数据流进行管理。</li>
</ul>
<p>4、功能可扩展性</p>
<ul>
<li>用户可以根据需要添加自己的agent，collector或者storage。</li>
<li>此外，Flume自带了很多组件，包括各种agent（file， syslog等），collector和storage（file，HDFS等）。</li>
</ul>
<p>5、文档丰富，社区活跃<br>Flume 已经成为 Hadoop 生态系统的标配，它的文档比较丰富，社区比较活跃，方便我们学习。</p>
<h3 id="flume-agent"><a href="#flume-agent" class="headerlink" title="flume agent"></a>flume agent</h3><p>Flume agent每个agent是一个独立的Java进程，从客户端（其他agent）接收数据然后转发到下一个destination（sink(沉槽) | agent）<br>Agent包含三个组件:</p>
<ul>
<li>A. Source（源）-&gt;生成数据的地方</li>
</ul>
<blockquote>
<p>从事件生成器接收数据，以event事件的形式传给一个或多个channel</p>
</blockquote>
<ul>
<li>B. Channel（通道）</li>
</ul>
<blockquote>
<p>从source中接受flume event，作为临时存放地，缓存到buffer中，直到sink<br>将其消费掉，是source和sink之间的桥梁<br>Channel是事务的，可以和多个source或sink协同</p>
</blockquote>
<ul>
<li>C.sink（沉槽）</li>
</ul>
<blockquote>
<p>存放数据到HDFS，从channel中消费event，并分发给destination，sink的<br>Destination 也可以是另一个agent或者HDFS，HBASE<br>注意：一个flume的agent，可以有多个source，channel，sink</p>
</blockquote>
<h3 id="flume核心组件介绍"><a href="#flume核心组件介绍" class="headerlink" title="flume核心组件介绍"></a>flume核心组件介绍</h3><p>Source： 完成对日志数据的收集，分成transtion 和 event 打入到channel之中， Flume提供了各种source的实现，包括Avro Source、 Exce Source、 Spooling<br>Directory Source、 NetCat Source、 Syslog Source、 Syslog TCP Source、Syslog UDP Source、 HTTP Source、 HDFS Source， etc。</p>
<p>Channel： Channel用于连接Source和Sink，Source将日志信息发送到Channel，Sink从Channel消费日志信息；Channel是中转日志信息的一个临时存储，保存有Source组件传递过来的日志信息。， flume提供了Memory Channel、 JDBC Chanel、 File Channel，etc</p>
<p>Sink： Flume Sink取出Channel中的数据，进行相应的存储文件系统，数据库，或者提交到远程服务器。包括HDFS sink、 Logger sink、 Avro sink、 File Roll sink、 Null sink、 HBasesink， etc。</p>
<h2 id="flume安装"><a href="#flume安装" class="headerlink" title="flume安装"></a>flume安装</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"># 下载</span><br><span class="line">get http://mirrors.tuna.tsinghua.edu.cn/apache/flume/1.8.0/apache-flume-1.8.0-bin.tar.gz</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 解压</span><br><span class="line">tar –zxvf apache-flume-1.8.0-bin.tar.gz</span><br><span class="line"></span><br><span class="line"># 添加配置文件（读取指定文件写入HDFS中）</span><br><span class="line"></span><br><span class="line"># Name the components on this agent</span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"># Describe/configure the source</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type = exec</span><br><span class="line">a1.sources.r1.command = tail -F /export/logs/web.log</span><br><span class="line"></span><br><span class="line"># Describe the sink</span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path =hdfs://node-1:9000/app_log/%y-%m-%d/%H-%M</span><br><span class="line"># 保存到HDFS上的前缀</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix = weichat_log</span><br><span class="line">a1.sinks.k1.hdfs.fileSuffix = .dat</span><br><span class="line">a1.sinks.k1.hdfs.batchSize= 100</span><br><span class="line">a1.sinks.k1.hdfs.fileType = DataStream</span><br><span class="line">a1.sinks.k1.hdfs.writeFormat =Text</span><br><span class="line"></span><br><span class="line"># 配置存储在HDFS上的文件大小单位(bytes)</span><br><span class="line">a1.sinks.k1.hdfs.rollSize = 262144</span><br><span class="line"># 写入多少个event数据后滚动文件(事件个数)</span><br><span class="line">a1.sinks.k1.hdfs.rollCount = 10</span><br><span class="line"># 文件滚动之前的等待时间(秒)</span><br><span class="line">a1.sinks.k1.hdfs.rollInterval = 120</span><br><span class="line"></span><br><span class="line"># 1分钟就改目录（创建目录）</span><br><span class="line">a1.sinks.k1.hdfs.round = true</span><br><span class="line">a1.sinks.k1.hdfs.roundValue = 1</span><br><span class="line">a1.sinks.k1.hdfs.roundUnit = minute</span><br><span class="line"></span><br><span class="line">a1.sinks.k1.hdfs.useLocalTimeStamp = true</span><br><span class="line"></span><br><span class="line"># Use a channel which buffers events in memory</span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"># Bind the source and sink to the channel</span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 添加配置文件（读取指定目录写入HDFS中）</span><br><span class="line"></span><br><span class="line">#定义三大组件的名称</span><br><span class="line">ag1.sources = source1</span><br><span class="line">ag1.sinks = sink1</span><br><span class="line">ag1.channels = channel1</span><br><span class="line"></span><br><span class="line"># 配置source组件</span><br><span class="line">ag1.sources.source1.type = spooldir</span><br><span class="line">ag1.sources.source1.spoolDir = /export/logs/</span><br><span class="line">ag1.sources.source1.fileSuffix=.FINISHED</span><br><span class="line">ag1.sources.source1.deserializer.maxLineLength=5120</span><br><span class="line"></span><br><span class="line"># 配置sink组件</span><br><span class="line">ag1.sinks.sink1.type = hdfs</span><br><span class="line">ag1.sinks.sink1.hdfs.path =hdfs://hdp-01:9000/access_log/%y-%m-%d/%H-%M</span><br><span class="line">ag1.sinks.sink1.hdfs.filePrefix = app_log</span><br><span class="line">ag1.sinks.sink1.hdfs.fileSuffix = .log</span><br><span class="line">ag1.sinks.sink1.hdfs.batchSize= 100</span><br><span class="line">ag1.sinks.sink1.hdfs.fileType = DataStream</span><br><span class="line">ag1.sinks.sink1.hdfs.writeFormat =Text</span><br><span class="line"></span><br><span class="line">## roll：滚动切换：控制写文件的切换规则</span><br><span class="line">## 按文件体积（字节）来切   </span><br><span class="line">ag1.sinks.sink1.hdfs.rollSize = 512000    </span><br><span class="line">## 按event条数切</span><br><span class="line">ag1.sinks.sink1.hdfs.rollCount = 1000000  </span><br><span class="line">## 按时间间隔切换文件</span><br><span class="line">ag1.sinks.sink1.hdfs.rollInterval = 60    </span><br><span class="line"></span><br><span class="line">## 控制生成目录的规则</span><br><span class="line">ag1.sinks.sink1.hdfs.round = true</span><br><span class="line">ag1.sinks.sink1.hdfs.roundValue = 10</span><br><span class="line">ag1.sinks.sink1.hdfs.roundUnit = minute</span><br><span class="line"></span><br><span class="line">ag1.sinks.sink1.hdfs.useLocalTimeStamp = true</span><br><span class="line"></span><br><span class="line"># channel组件配置</span><br><span class="line">ag1.channels.channel1.type = memory</span><br><span class="line">## event条数</span><br><span class="line">ag1.channels.channel1.capacity = 500000   </span><br><span class="line">##flume事务控制所需要的缓存容量600条event</span><br><span class="line">ag1.channels.channel1.transactionCapacity = 600  </span><br><span class="line"></span><br><span class="line"># 绑定source、channel和sink之间的连接</span><br><span class="line">ag1.sources.source1.channels = channel1</span><br><span class="line">ag1.sinks.sink1.channel = channel1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 启动flume</span><br><span class="line"></span><br><span class="line">$FLUME_HOME/bin/flume-ng agent -c conf -f conf/tail-hdfs.conf -n a1 -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/02/04/flume/" data-id="cjrqbftxu000dakc4ml7c3c9n" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Docker" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/02/04/Docker/" class="article-date">
  <time datetime="2019-02-04T12:16:13.762Z" itemprop="datePublished">2019-02-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>title: CentOS<br>date: 2018-01-05 12:31:12<br>tags: [linux, shell, CentOS]<br>categories: linux</p>
<h1 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h1><h2 id="Docker-核心概念及入门"><a href="#Docker-核心概念及入门" class="headerlink" title="Docker 核心概念及入门"></a>Docker 核心概念及入门</h2><h3 id="什么是docker"><a href="#什么是docker" class="headerlink" title="什么是docker"></a>什么是docker</h3><p>Docker是一个开放源代码软件项目，让应用程序布署在软件货柜下的工作可以自动化进行，借此在Linux操作系统上，提供一个额外的软件抽象层，以及操作系统层虚拟化的自动管理机制。Docker利用Linux核心中的资源分离机制，例如cgroups，以及Linux核心名字空间（namespaces），来创建独立的容器（containers）。这可以在单一Linux实体下运作，避免启动一个虚拟机造成的额外负担。Linux核心对名字空间的支持完全隔离了工作环境中应用程序的视野，包括进程树、网络、用户ID与挂载文件系统，而核心的cgroup提供资源隔离，包括CPU、存储器、block I/O与网络。从0.9版本起，Dockers在使用抽象虚拟是经由libvirt的LXC与systemd - nspawn提供界面的基础上，开始包括libcontainer库做为以自己的方式开始直接使用由Linux核心提供的虚拟化的设施，</p>
<h3 id="Docker-版本简介"><a href="#Docker-版本简介" class="headerlink" title="Docker 版本简介"></a>Docker 版本简介</h3><p>Docker有两个版本：<br>社区版（CE）<br>企业版（EE）<br>Docker Community Edition（CE）非常适合希望开始使用Docker并尝试使用基于容器的应用程序的个人开发人员和小型团队。</p>
<p>Docker企业版（EE）专为企业开发和IT团队而设计，他们可以在生产中大规模构建，发布和运行业务关键型应用程序</p>
<table>
<thead>
<tr>
<th>功能</th>
<th>社区版</th>
<th>企业版基础版</th>
<th>企业版标准</th>
<th>企业版高级版</th>
</tr>
</thead>
<tbody>
<tr>
<td>容器引擎和内置编排，网络，安全性</td>
<td>是</td>
<td>是</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>经过认证的基础设施，插件和ISV容器</td>
<td>否</td>
<td>是</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>图像管理</td>
<td>否</td>
<td>否</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>容器应用管理</td>
<td>否</td>
<td>否</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>图像安全扫描</td>
<td>否</td>
<td>否</td>
<td>否</td>
<td>是</td>
</tr>
</tbody>
</table>
<h3 id="关于容器技术的介绍及概念"><a href="#关于容器技术的介绍及概念" class="headerlink" title="关于容器技术的介绍及概念"></a>关于容器技术的介绍及概念</h3><ul>
<li>容器技术<br>Linux容器技术很早就有了，比较有名的是被集成到主流Linux内核中的LXC项目。容器通过对操作系统的资源访问进行限制，构建成独立的资源池，让应用运行在一个相对隔离的空间里，同时容器间也可以进行通信。容器技术对比虚拟化技术，容器比虚拟化更轻量级，对资源的消耗小很多。容器操作也更快捷，启动和停止都要比虚拟机快。但Docker容器需要与主机共享操作系统内核，不能像虚拟机那样运行独立的内核。<br>Docker是一个基于LXC技术构建的容器引擎，基于GO语言开发，遵循Apache2.0协议开源。Docker的发展得益于为使用者提供了更好的容器操作接口。包括一系列的容器，镜像，网络等管理工具，可以让用户简单的创建和使用容器。<br>Docker支持将应用打包进一个可以移植的容器中，重新定义了应用开发，测试，部署上线的过程，核心理念就是 Build once, Run anywhere。Docker容器技术的典型应用场景是开发运维上提供持续集成和持续部署的服务。</li>
<li>镜像<br>Docker的镜像概念类似于虚拟机里的镜像，是一个只读的模板，一个独立的文件系统，包括运行容器所需的数据，可以用来创建新的容器。镜像可以基于Dockerfile构建，Dockerfile是一个描述文件，里面包含若干条命令，每条命令都会对基础文件系统创建新的层次结构。用户可以通过编写Dockerfile创建新的镜像，也可以直接从类似github的Docker Hub上下载镜像使用。</li>
<li>容器<br>Docker容器是由Docker镜像创建的运行实例。Docker容器类似虚拟机，可以支持的操作包括启动，停止，删除等。每个容器间是相互隔离的，但隔离的效果比不上虚拟机。容器中会运行特定的应用，包含特定应用的代码及所需的依赖文件。<br>在Docker容器中，每个容器之间的隔离使用Linux的 CGroups 和 Namespaces技术实现的。其中 CGroups 对CPU，内存，磁盘等资源的访问限制，Namespaces 提供了环境的隔离。</li>
<li>仓库<br>如果你使用过 git 和 github 就很容易理解Docker的仓库概念。Docker仓库相当于一个 github 上的代码库。<br>Docker 仓库是用来包含镜像的位置，Docker提供一个注册服务器（Registry）来保存多个仓库，每个仓库又可以包含多个具备不同tag的镜像。Docker运行中使用的默认仓库是 Docker Hub 公共仓库。仓库支持的操作类似 git，创建了新的镜像后，我们可以 push 提交到仓库，也可以从指定仓库 pull 拉取镜像到本地。</li>
</ul>
<p><strong>Docker有下面这些组成</strong></p>
<p>1.Docker 服务器守护程序（server daemon），用于管理所有的容器。</p>
<p>2.Docker 命令行客户端，用于控制服务器守护程序。</p>
<p>3.Docker 镜像：查找和浏览 docker 容器镜像。</p>
<p><strong>Docker特性</strong></p>
<p>文件系统隔离：每个进程容器运行在完全独立的根文件系统里。</p>
<p>资源隔离：可以使用cgroup为每个进程容器分配不同的系统资源，例如CPU和内存。</p>
<p>网络隔离：每个进程容器运行在自己的网络命名空间里，拥有自己的虚拟接口和IP地址。</p>
<p>写时复制：采用写时复制方式创建根文件系统，这让部署变得极其快捷，并且节省内存和硬盘空间。</p>
<p>日志记录：Docker将会收集和记录每个进程容器的标准流（stdout/stderr/stdin），用于实时检索或批量检索。</p>
<p>变更管理：容器文件系统的变更可以提交到新的映像中，并可重复使用以创建更多的容器。无需使用模板或手动配置。</p>
<p>交互式Shell：Docker可以分配一个虚拟终端并关联到任何容器的标准输入上，例如运行一个一次性交互shell。</p>
<p><strong>Docker两个基础概念images与container</strong></p>
<p>Container和Image 在Docker的世界里，Image是指一个只读的层（Layer），这里的层是AUFS里的概念，最直观的方式就是看一下docker官方给出的图：</p>
<p>Docker使用了一种叫AUFS的文件系统，这种文件系统可以让你一层一层地叠加修改你的文件，最底下的文件系统是只读的，如果需要修改文件，AUFS 会增加一个可写的层（Layer），这样有很多好处，例如不同的Container可以共享底层的只读文件系统（同一个Kernel），使得你可以跑N多 个Container而不至于你的硬盘被挤爆了！这个只读的层就是Image！而如你所看到的，一个可写的层就是Container。</p>
<p>那Image和Container的区别是什么？很简单，他们的区别仅仅是一个是只读的层，一个是可写的层，你可以使用docker commit 命令，将你的Container变成一个Image，也就是提交你所运行的Container的修改内容，变成一个新的只读的Image，这非常类似于git commit命令。 </p>
<h3 id="前置准备和安装Docker（基于CentOS-7-安装-Docker-CE"><a href="#前置准备和安装Docker（基于CentOS-7-安装-Docker-CE" class="headerlink" title="前置准备和安装Docker（基于CentOS 7 安装 Docker CE)"></a>前置准备和安装Docker（基于CentOS 7 安装 Docker CE)</h3><p>Docker 要求 CentOS 系统的内核版本高于 3.10 ，安装前需要验证 CentOS 版本是否支持 Docker。</p>
<p>命令查看你当前的内核版本</p>
<ul>
<li><code>$ uname -r</code>       </li>
</ul>
<p>更新yum</p>
<ul>
<li><code>$ sudo yum makecache fast</code></li>
</ul>
<p>安装yum-utils</p>
<ul>
<li><code>$ sudo yum install yum-utils</code></li>
</ul>
<p>使用以下命令设置稳定存储库</p>
<ul>
<li><code>$ sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo</code></li>
</ul>
<p>卸载旧版本(如果安装过旧版本的话)</p>
<ul>
<li><code>$ sudo yum remove docker  docker-common docker-selinux docker-engine</code></li>
</ul>
<p>安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的</p>
<ul>
<li><code>$ sudo yum install -y yum-utils device-mapper-persistent-data lvm2</code></li>
</ul>
<p>安装Docker</p>
<ul>
<li><code>sudo yum install docker-ce</code></li>
</ul>
<p>启动、停止、重启Docker服务</p>
<ul>
<li><code>$systemctl start | stop | restart  docker.service</code></li>
</ul>
<p>设置开机启动、关闭服务</p>
<ul>
<li><code>$ systemctl enable | disable docker.service</code></li>
</ul>
<p>验证安装是否成功(有client和service两部分表示docker安装启动都成功了)</p>
<ul>
<li><code>$ docker version</code></li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[root@localhost ~]# docker version</span><br><span class="line">Client:</span><br><span class="line"> Version:       18.03.0-ce</span><br><span class="line"> API version:   1.37</span><br><span class="line"> Go version:    go1.9.4</span><br><span class="line"> Git commit:    0520e24</span><br><span class="line"> Built: Wed Mar 21 23:09:15 2018</span><br><span class="line"> OS/Arch:       linux/amd64</span><br><span class="line"> Experimental:  false</span><br><span class="line"> Orchestrator:  swarm</span><br><span class="line"></span><br><span class="line">Server:</span><br><span class="line"> Engine:</span><br><span class="line">  Version:      18.03.0-ce</span><br><span class="line">  API version:  1.37 (minimum version 1.12)</span><br><span class="line">  Go version:   go1.9.4</span><br><span class="line">  Git commit:   0520e24</span><br><span class="line">  Built:        Wed Mar 21 23:13:03 2018</span><br><span class="line">  OS/Arch:      linux/amd64</span><br><span class="line">  Experimental: false</span><br><span class="line">[root@localhost ~]#</span><br></pre></td></tr></table></figure>
<p>docker通过运行hello-world 映像验证是否已正确安装。</p>
<ul>
<li><code>$ sudo docker run hello-world</code></li>
</ul>
<h3 id="Docker的常用操作"><a href="#Docker的常用操作" class="headerlink" title="Docker的常用操作"></a>Docker的常用操作</h3><p><strong>获取镜像</strong></p>
<p>搜索镜像(我这里搜索的是tomcat的镜像)</p>
<ul>
<li><code>$ docker search tomcat</code></li>
</ul>
<p>下载镜像(在搜索出来的镜像列表中选择一个下载，我这里下载的是官方提供的centos镜像，速度会有点慢，耐心等待)</p>
<ul>
<li><code>$ docker pull tomcat</code></li>
</ul>
<p>列出本机的镜像</p>
<ul>
<li><code>$ docker images</code></li>
</ul>
<p>基于image创建一个容器，运行完毕后并退出</p>
<ul>
<li><code>$ docker run [centos] /bin/echo &#39;Hello world&#39;</code></li>
</ul>
<p>运行一个交互式容器,-t表示指定一个容器内的伪tty。-i表示创建一个交互式连接,命令运行后，将会进入shell交互式界面，可执行任意的命令.</p>
<ul>
<li><code>$ docker run -t -i centos /bin/bash</code></li>
</ul>
<p>创建一个带名字的容器</p>
<ul>
<li><code>$ docker run -d --name myweb centos /bin/bash</code></li>
</ul>
<p>开始/停止/强制停止/重启一个的容器</p>
<ul>
<li><code>$ docker start/stop/kill/restart [container]</code></li>
</ul>
<p>删除一个容器</p>
<ul>
<li><code>$ docker rm [container]</code></li>
</ul>
<p>进入容器内容</p>
<ul>
<li><code>docker exec -it [container] /bin/bash</code></li>
</ul>
<p>如果指定-a参数，则列出所有状态下的容器，包含处于stop状态的容器。如果没有带-a参数，则只显示出处于运行状态的容器。-l参数表示只列出最后一个启动的容器。</p>
<ul>
<li><code>$ docker ps [-a] [-l]</code></li>
</ul>
<h2 id="docker容器的常用软件安装过程"><a href="#docker容器的常用软件安装过程" class="headerlink" title="docker容器的常用软件安装过程"></a>docker容器的常用软件安装过程</h2><h3 id="docker中运行mysql"><a href="#docker中运行mysql" class="headerlink" title="docker中运行mysql"></a>docker中运行mysql</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=[password] -v /xxx/mysql:/var/lib/mysql -v /etc/my.cnf:/etc/my.cnf mysql:5.7.23 </span><br><span class="line"></span><br><span class="line">create user &apos;user&apos;@&apos;%&apos; identified by &apos;password&apos;;</span><br><span class="line"></span><br><span class="line">grant replication slave on *.* to &apos;user&apos;@&apos;%&apos;;</span><br><span class="line"></span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>
<h3 id="docker中运行redis"><a href="#docker中运行redis" class="headerlink" title="docker中运行redis"></a>docker中运行redis</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name redis -p 6379:6379 -v /xxx/data/redis:/data redis redis-server --appendonly yes --requirepass &quot;[password]&quot;</span><br><span class="line"></span><br><span class="line">docker run \</span><br><span class="line">-p 6379:6379 \          # 端口映射 宿主机:容器</span><br><span class="line">-v /xxx/data:/data:rw \ # 映射数据目录 rw 为读写</span><br><span class="line">-v /xxx/conf/redis.conf:/etc/redis/redis.conf:ro \ # 挂载配置文件 ro 为readonly</span><br><span class="line">--privileged=true \     # 给与一些权限</span><br><span class="line">--name redis \          # 给容器起个名字</span><br><span class="line">--appendonly yes \      # 开启数据持久化</span><br><span class="line">-d redis redis-server /xxx/conf/redis.conf # deamon 运行 服务使用指定的配置文件</span><br></pre></td></tr></table></figure>
<h3 id="docker中运行nexus"><a href="#docker中运行nexus" class="headerlink" title="docker中运行nexus"></a>docker中运行nexus</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 8080:8080 --name nexus -v /xxx/nexus:/var/nexus-data --restart=always sonatype/nexus3</span><br></pre></td></tr></table></figure>
<h3 id="docker中运行Jenkins"><a href="#docker中运行Jenkins" class="headerlink" title="docker中运行Jenkins"></a>docker中运行Jenkins</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 8080:8080 -p 50000:50000 --name jenkins --privileged=true  -v /xxx/jenkins:/var/jenkins_home jenkins</span><br></pre></td></tr></table></figure>
<h3 id="docker中安装gitlab"><a href="#docker中安装gitlab" class="headerlink" title="docker中安装gitlab"></a>docker中安装gitlab</h3><p>docker run –detach \<br>    –hostname 120.76.77.230 \<br>    –publish 444:443 –publish 8088:8088 –publish 25:22 \<br>    –name gitlab \<br>    –restart always \<br>    –volume /xxx/gitlab/config:/etc/gitlab \<br>    –volume /xxx/gitlab/logs:/var/log/gitlab \<br>    –volume /xxx/gitlab/data:/var/opt/gitlab \<br>    gitlab/gitlab-ce:latest</p>
<h3 id="docker中运行java"><a href="#docker中运行java" class="headerlink" title="docker中运行java"></a>docker中运行java</h3><p>some-mysql： 容器别名<br>my-secret-pw：初始化设置的root用户的密码<br>tag：mysql的版本，不写默认使用最新版<br>-p 3306:3306：表示在这个容器中使用3306端口(第二个)映射到本机的端口号也为3306(第一个)</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/02/04/Docker/" data-id="cjrqbftya000kakc408chbo1n" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/4/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="page-number current">5</span>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/02/04/Crontab/">(no title)</a>
          </li>
        
          <li>
            <a href="/2019/02/04/CentOS-7.5-init/">(no title)</a>
          </li>
        
          <li>
            <a href="/2019/02/04/bash/">(no title)</a>
          </li>
        
          <li>
            <a href="/2019/02/04/awk/">(no title)</a>
          </li>
        
          <li>
            <a href="/2019/02/04/后台项目技术规范/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>